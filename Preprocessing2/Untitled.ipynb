{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import Counter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_hash_tokenize(tweet):\n",
    "    new = tweet.replace('#', '')\n",
    "    return new.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = '../data/'\n",
    "pos = np.asarray([line.rstrip('\\n').lower() for line in open(BASE+'train_pos_full.txt', encoding='utf8')])\n",
    "neg = np.asarray([line.rstrip('\\n').lower() for line in open(BASE+'train_neg_full.txt', encoding='utf8')])\n",
    "test = np.asarray([line.rstrip('\\n').lower() for line in open(BASE+'test_data.txt', encoding='utf8')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tkn = [remove_hash_tokenize(tweet) for tweet in pos] \n",
    "neg_tkn = [remove_hash_tokenize(tweet) for tweet in neg] \n",
    "test_tkn = [remove_hash_tokenize(tweet) for tweet in test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tkn = [w for tokens in pos_tkn+neg_tkn+test_tkn for w in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39499657"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tkn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "571468"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkn_counter = Counter(all_tkn)\n",
    "len(tkn_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Diictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upload_dict(file, BASE = './dict/', hltud=False):\n",
    "    path = BASE + file\n",
    "    words = np.asarray([line.rstrip('\\n').lower() for line in open(path)])\n",
    "    if hltud:\n",
    "        keys = [w.split()[1] for w in words]\n",
    "        values = [w.split()[3] for w in words]\n",
    "    else:\n",
    "        keys = [w.split()[0] for w in words]\n",
    "        values = [w.split()[1] for w in words]\n",
    "    return dict(zip(keys, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emnlp = upload_dict('emnlp_dict.txt')\n",
    "luulu = upload_dict('luulu_typo-corpus-r1.txt')\n",
    "hltd = upload_dict('hltutdallas.txt', hltud=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell_dict = set(list(luulu)+list(emnlp)+list(hltd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49349"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spell_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### upload english dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = '../data/dictionaries/'\n",
    "english_words = np.asarray([line.rstrip('\\n').lower() for line in open(BASE+'english_words.txt')])\n",
    "idx = np.arange(int(len(english_words)/3))\n",
    "english_dictionary = dict(zip(english_words[3*idx+1], english_words[3*idx+1]))\n",
    "freq =  dict(zip(english_words[3*idx+1], english_words[3*idx+2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36662, 36662)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_dictionary), len(set(english_dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### upload acronyms / smileys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct(sentence, contrac_dict={}):\n",
    "\t'replace contractions in sentence and remove punctuation'\n",
    "\ttokens = sentence.split()\n",
    "\tnew_tokens = []\n",
    "\tfor token in tokens:\n",
    "\t\tif token in contrac_dict:\n",
    "\t\t\tnew_tokens.append(contrac_dict[token])\n",
    "\t\tif len(token)>1:\n",
    "\t\t\tnew_tokens.append(''.join(c for c in token if c not in string.punctuation))\n",
    "\treturn ' '.join(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Acronyms\n",
    "acronyms = np.asarray([line.rstrip('\\n').lower() for line in open(BASE+'netlingo_acronyms.txt')])\n",
    "idx = np.arange(int(len(acronyms)/2))\n",
    "acronyms_dict = dict(zip(acronyms[2*idx], acronyms[2*idx+1]))\n",
    "#Remove multi explications\n",
    "for key in acronyms_dict:\n",
    "\tacronyms_dict[key] = acronyms_dict[key].split('/ ')[0]\n",
    "  #correct descriptions\n",
    "for key in acronyms_dict:\n",
    "\tacronyms_dict[key] = correct(acronyms_dict[key])\n",
    "\n",
    "## Smileys\n",
    "smileys = np.asarray([line.rstrip('\\n').lower() for line in open(BASE+'netlingo_smileys.txt')])\n",
    "idx = np.arange(int(len(smileys)/2))\n",
    "smileys_dict = dict(zip(smileys[2*idx], smileys[2*idx+1]))\n",
    "#Remove multi explications\n",
    "for key in smileys_dict:\n",
    "\tsmileys_dict[key] = smileys_dict[key].split('- ')[0]\n",
    "#remove '-' from smiley and add it\n",
    "keys = list(smileys_dict.keys())\n",
    "for s in keys:\n",
    "    if '-' in s and len(s)>2:\n",
    "        smileys_dict[s.replace('-', '')] = smileys_dict[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5032, 412)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acronyms), len(smileys_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_presence(tkn_counter, word_dict):\n",
    "    count = 0\n",
    "    for w in tkn_counter:\n",
    "        if w in word_dict:\n",
    "            count += tkn_counter[w]\n",
    "    print('{}% found'.format(round(count*100/sum(tkn_counter.values()), 2)))\n",
    "\n",
    "def get_unknown_words(tkn_counter, word_dict, Threshold=100):\n",
    "    unknown_words = []\n",
    "    for w in tkn_counter:\n",
    "        if w not in word_dict and len(w)<=Threshold:\n",
    "            unknown_words.append(w)\n",
    "    return unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.14% found\n"
     ]
    }
   ],
   "source": [
    "count_presence(tkn_counter, spell_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.16% found\n"
     ]
    }
   ],
   "source": [
    "count_presence(tkn_counter, english_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = list(english_dictionary.keys())+list(spell_dict)+list(smileys_dict.keys())+list(acronyms_dict.keys())\n",
    "tmp = set(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.73% found\n"
     ]
    }
   ],
   "source": [
    "count_presence(tkn_counter, tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "803"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown = get_unknown_words(tkn_counter, tmp, 2)\n",
    "len(unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.817214362139904"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([tkn_counter[w] for w in unknown])*100/len(all_tkn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in list(tkn_counter.keys()):\n",
    "    if w in unknown:\n",
    "        del tkn_counter[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.87% found\n"
     ]
    }
   ],
   "source": [
    "count_presence(tkn_counter, tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown = get_unknown_words(tkn_counter, tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<user>',\n",
       " 'tsk',\n",
       " '<url>',\n",
       " 'casper',\n",
       " 'crakkbitch',\n",
       " \"don't\",\n",
       " '...',\n",
       " 'lifecompleted',\n",
       " 'facebook',\n",
       " '1dnextalbumtitle',\n",
       " 'rollercoaster',\n",
       " 'cocept',\n",
       " 'followmeplz',\n",
       " 'x15',\n",
       " 'coworker',\n",
       " 'replying',\n",
       " 'nationals2013',\n",
       " 'finna',\n",
       " 'monet',\n",
       " 'katemelo',\n",
       " 'arrived',\n",
       " 'yeslord',\n",
       " 'barca',\n",
       " 'grains',\n",
       " 'jaeyay',\n",
       " 'werna',\n",
       " 'khatam',\n",
       " 'hojaeygi',\n",
       " 'baaqi',\n",
       " 'buttering',\n",
       " 'karaygay',\n",
       " 'sab',\n",
       " 'mid-term',\n",
       " \"i'm\",\n",
       " '10:30-',\n",
       " '2:30',\n",
       " '16millionbritneyfan',\n",
       " \"it's\",\n",
       " \":')\",\n",
       " 'pros',\n",
       " 'mikes',\n",
       " \"q's\",\n",
       " '4/20',\n",
       " 'reasons2dothebirdmanhandrub',\n",
       " 'lols',\n",
       " 'tomlinson',\n",
       " 'bigger',\n",
       " 'yougetmajorpointsif',\n",
       " 'southall',\n",
       " \"let's\",\n",
       " 'followers',\n",
       " '500',\n",
       " 'teamjessie',\n",
       " 'thevoiceuk',\n",
       " 'schmidt',\n",
       " 'charmer',\n",
       " 'gazillion',\n",
       " 'kills',\n",
       " 'buddy',\n",
       " 'zuers',\n",
       " 'midterms',\n",
       " 'twfanmily',\n",
       " 'figured',\n",
       " 'starts',\n",
       " 'tweets',\n",
       " 'xoxoxo',\n",
       " 'aww',\n",
       " 'lifts',\n",
       " 'toes',\n",
       " '4.20',\n",
       " 'sparking',\n",
       " 'jaomikay',\n",
       " 'kathrynbernardoasmikay',\n",
       " 'thankyou',\n",
       " '40s',\n",
       " 'gunun',\n",
       " 'sorusu',\n",
       " 'via',\n",
       " 'bieber',\n",
       " 'assumed',\n",
       " 'chikaroo',\n",
       " 'nitrous',\n",
       " \"dm'd\",\n",
       " 'pwede',\n",
       " 'malamig',\n",
       " 'haist',\n",
       " '9:19',\n",
       " 'sweetz',\n",
       " 'foreveralone',\n",
       " 'hahahah',\n",
       " 'insommia',\n",
       " 'lifeofcallcenter',\n",
       " 'swiftie',\n",
       " 'dadforgottogetkerosine',\n",
       " 'trending',\n",
       " 'stupidhashtag',\n",
       " '<---',\n",
       " 'wishfulthinking',\n",
       " 'kimmy',\n",
       " 'rouninblogs',\n",
       " 'stickers',\n",
       " 'rouninapparel',\n",
       " 'rounin',\n",
       " 'deserves',\n",
       " 'mhee',\n",
       " 'mhy',\n",
       " 'msh',\n",
       " 'aja',\n",
       " 'lipbalm',\n",
       " 'salep',\n",
       " 'kutu',\n",
       " 'miss',\n",
       " 'problem',\n",
       " 'workflow',\n",
       " 'playlist',\n",
       " \"you're\",\n",
       " 'blacky',\n",
       " 'xoxox',\n",
       " 'pycc',\n",
       " 'toolive',\n",
       " 'realthug',\n",
       " 'mayo',\n",
       " 'whewww',\n",
       " 'thingsrkellysingsabout',\n",
       " 'laynn',\n",
       " 'briefs',\n",
       " 'instagram',\n",
       " 'imma',\n",
       " 'righthaha',\n",
       " 'reassuringly',\n",
       " 'trotskyist',\n",
       " 'treats',\n",
       " 'woohoo',\n",
       " 'waystobeginsex',\n",
       " 'bap',\n",
       " '1love',\n",
       " 'banglorean',\n",
       " 'icecream',\n",
       " 'infused',\n",
       " 'joketweet',\n",
       " 'imintoyou',\n",
       " 'advisory',\n",
       " 'fans',\n",
       " 'jackasses',\n",
       " 'inlove',\n",
       " 'ritika',\n",
       " 'wannabeees',\n",
       " 'snooks',\n",
       " 'careers',\n",
       " 'awww',\n",
       " 'minaj',\n",
       " 'starships',\n",
       " 'hugs',\n",
       " 'hotbox',\n",
       " 'hits',\n",
       " \"me'll\",\n",
       " '1dwebstersurfboards',\n",
       " 'avi',\n",
       " 'seaworld',\n",
       " 'joking',\n",
       " 'boo',\n",
       " 'reminds',\n",
       " 'tele',\n",
       " 'hahahaha',\n",
       " 'garret',\n",
       " 'sleeps',\n",
       " 'hittheroadjack',\n",
       " 'aches',\n",
       " 'staage',\n",
       " 'hitman',\n",
       " '5am',\n",
       " 'audition',\n",
       " 'playipad',\n",
       " 'failures',\n",
       " 'wahh',\n",
       " 'fights',\n",
       " 'pussies',\n",
       " 'perving',\n",
       " 'liam',\n",
       " 'spending',\n",
       " 'lew',\n",
       " 'gingey',\n",
       " 'popping',\n",
       " 'goodnight',\n",
       " \"y'all\",\n",
       " 'ninie',\n",
       " 'segyero',\n",
       " 'banged',\n",
       " 'kindalethal',\n",
       " 'boothes',\n",
       " 'regents',\n",
       " 'chegg',\n",
       " 'nupe',\n",
       " 'cba',\n",
       " 'pandora',\n",
       " 'pinterest',\n",
       " 'b1tch3zz',\n",
       " 'travaglini',\n",
       " 'charley',\n",
       " 'dankitydank',\n",
       " 'shmoked',\n",
       " 'fuckswithme',\n",
       " 'loveeeyou',\n",
       " 'ziall',\n",
       " 'tixbox',\n",
       " 'rkm',\n",
       " 'unpad',\n",
       " 'dipatiukur',\n",
       " 'bandung',\n",
       " 'madison',\n",
       " 'througt',\n",
       " '444',\n",
       " 'tweeenty',\n",
       " 'cutey',\n",
       " 'hicks',\n",
       " 'nigga',\n",
       " '50liesiwastold',\n",
       " 'iwantthe1dbook',\n",
       " 'jaden',\n",
       " 'hamoswant1dtour',\n",
       " 'drewett',\n",
       " \"biersack's\",\n",
       " 'i-set',\n",
       " 'naten',\n",
       " 'paalam',\n",
       " 'mahehehehhe',\n",
       " '>:d',\n",
       " 'oomf',\n",
       " \"sam's\",\n",
       " 'ahahahha',\n",
       " 'piercings',\n",
       " 'ifindthatattractive',\n",
       " 'yves',\n",
       " 'pbbteens4',\n",
       " 'yaya',\n",
       " 'responding',\n",
       " 'wasttteddd',\n",
       " 'mavs',\n",
       " 'perfecting',\n",
       " 'scotlandaintready',\n",
       " 'bismillah',\n",
       " 't4otb',\n",
       " \"tht's\",\n",
       " 'wednesday',\n",
       " 'doeee',\n",
       " \"sancha's\",\n",
       " 'deee',\n",
       " \"training's\",\n",
       " \"b's\",\n",
       " 'sabaw',\n",
       " 'loads',\n",
       " 'footballs',\n",
       " 'shots',\n",
       " 'urghh',\n",
       " 'unattractivethingsaboutme',\n",
       " 'texter',\n",
       " \"u're\",\n",
       " 'goodluckcharlieseason3premiere',\n",
       " 'reactions',\n",
       " 'haitians',\n",
       " 'babysitter',\n",
       " 'chiswick',\n",
       " 'horoscopes',\n",
       " 'justsayin',\n",
       " 'yosii',\n",
       " 'cornetto',\n",
       " 'enigmas',\n",
       " 'uhm',\n",
       " 'lorans',\n",
       " 'cyrus',\n",
       " \"payne's\",\n",
       " 'middlename',\n",
       " 'nicheke',\n",
       " 'mulika',\n",
       " 'mwizi',\n",
       " 'ehe',\n",
       " 'photos',\n",
       " 'getthegoodguy',\n",
       " 'leto',\n",
       " '18yrs',\n",
       " \"cd's\",\n",
       " 'vyrted',\n",
       " 'yummmp',\n",
       " 'fashionista',\n",
       " \"here's\",\n",
       " 'jaja',\n",
       " 'kath',\n",
       " 'hunnit',\n",
       " 'mothafuckazz',\n",
       " 'changed',\n",
       " 'twitcon',\n",
       " 'constructive',\n",
       " 'cluuue',\n",
       " 'familymenders',\n",
       " 'propa',\n",
       " 'shagger',\n",
       " 'entitled',\n",
       " 'trashing',\n",
       " 'jocelyn',\n",
       " 'koko',\n",
       " 'thedrybar',\n",
       " 'aquarians',\n",
       " 'ankles',\n",
       " 'oops',\n",
       " 'comedians',\n",
       " 'cooled',\n",
       " 'imlimitededition',\n",
       " \"everyone's\",\n",
       " 'albertooo',\n",
       " 'chrimas',\n",
       " 'retweet',\n",
       " \"90's\",\n",
       " 'babies',\n",
       " 'thoughtsduringschool',\n",
       " 'bella',\n",
       " 'diba',\n",
       " 'hoarder',\n",
       " 'sweats',\n",
       " 'cobeys',\n",
       " 'depicable',\n",
       " 'estimating',\n",
       " 'projectmanagement',\n",
       " 'a7x',\n",
       " 'athames',\n",
       " 'awhh',\n",
       " 'oopu',\n",
       " 'opesthunayi',\n",
       " 'epudu',\n",
       " 'yenti',\n",
       " 'malli.hehehe',\n",
       " 'pepople',\n",
       " 'fridayiminlove',\n",
       " 'coins',\n",
       " 'grinding',\n",
       " 'thongthursday',\n",
       " 'tweetybirds',\n",
       " 'salamat',\n",
       " 'updates',\n",
       " 'celebrating',\n",
       " '20th',\n",
       " '13th',\n",
       " 'afterward',\n",
       " 'sgtc',\n",
       " 'retweeting',\n",
       " 'queven',\n",
       " 'amari',\n",
       " 'flops',\n",
       " 'bwhahahahha',\n",
       " 'fingerscrossed',\n",
       " 'lauri',\n",
       " '142',\n",
       " 'reallythough',\n",
       " 'blerg',\n",
       " '358',\n",
       " 'lmmfaoo',\n",
       " 'aint',\n",
       " 'webbie',\n",
       " '7,665',\n",
       " '21st',\n",
       " 'chelsea',\n",
       " 'blinder',\n",
       " 'trapped',\n",
       " 'aheartforgod',\n",
       " 'spongbob',\n",
       " 'youaintnogoodif',\n",
       " 'rns',\n",
       " 'drugged',\n",
       " 'spelled',\n",
       " 'albums',\n",
       " 'asbo',\n",
       " 'ferrari-only',\n",
       " 'antype',\n",
       " 'musicians',\n",
       " '830',\n",
       " 'be-n',\n",
       " 'advicetewwhoevaneedsit',\n",
       " 'spoilers',\n",
       " 'ahh',\n",
       " 'readathon',\n",
       " 'alesg',\n",
       " 'rin',\n",
       " 'alam',\n",
       " 'bakit',\n",
       " 'wala',\n",
       " 'namang',\n",
       " 'obb',\n",
       " 'hairstyle',\n",
       " 'uhhh',\n",
       " '0_o',\n",
       " 'somemovie',\n",
       " 'brag',\n",
       " 'ruschers',\n",
       " '1.2',\n",
       " 'norwich',\n",
       " '29th',\n",
       " 'hby',\n",
       " 'everytime',\n",
       " '2aked',\n",
       " 'eny',\n",
       " 'table.tv.couch.bed',\n",
       " '195',\n",
       " 'noitsnotfordrugsoranythingbad',\n",
       " 'freeman',\n",
       " 'tryna',\n",
       " 'yeahs',\n",
       " 'ahaa',\n",
       " 'nialler',\n",
       " 'grinds',\n",
       " 'stripping',\n",
       " 'itunes',\n",
       " 'vern',\n",
       " \"who's\",\n",
       " 'happybirthday',\n",
       " 'airbag',\n",
       " 'applebutt',\n",
       " 'krisbian',\n",
       " 'tanning',\n",
       " 'tampa',\n",
       " 'physics',\n",
       " 'desirre',\n",
       " 'cdfu',\n",
       " 'inshallah',\n",
       " 'meditteranean',\n",
       " 'subtweets',\n",
       " 'subtweet',\n",
       " 'subconsciously',\n",
       " 'ahww',\n",
       " 'whatupwiththat',\n",
       " 'ohhh',\n",
       " 'megaramp',\n",
       " '2012',\n",
       " 'hueneme',\n",
       " \"tonight's\",\n",
       " 'gah',\n",
       " 'obama',\n",
       " 'teamleo',\n",
       " 'lmaoo',\n",
       " 'soyouknowitsreal',\n",
       " 'gracias',\n",
       " 'newtothis',\n",
       " 'crackyou',\n",
       " 'lmafoo',\n",
       " 'blacker',\n",
       " 'sweeter',\n",
       " 'ctfuu',\n",
       " 'statestreetdiner',\n",
       " 'iloveitwhen',\n",
       " 'wna',\n",
       " 'blair',\n",
       " 'cantbearblair',\n",
       " 'reggae',\n",
       " 'ahhh',\n",
       " 'thepolice',\n",
       " 'bobmarley',\n",
       " 'thedoors',\n",
       " 'rollingstones',\n",
       " 'mudheng',\n",
       " '11:11',\n",
       " 'uwi',\n",
       " 'tayo',\n",
       " 'sheyver',\n",
       " 'kayo',\n",
       " '1th',\n",
       " 'monthsary',\n",
       " 'napanuodan',\n",
       " 'subs',\n",
       " \"eli's\",\n",
       " 'lolll',\n",
       " 'maica',\n",
       " 'follback',\n",
       " 'tybfr',\n",
       " 'tootsie',\n",
       " 'callmyname',\n",
       " 'tuesday',\n",
       " 'gays',\n",
       " 'hannahwaite',\n",
       " 'chanicekett',\n",
       " 'anniemurdoch',\n",
       " 'lucyyoung',\n",
       " 'flllyyinnnggg',\n",
       " 'boythudervisitsgyss',\n",
       " 'visits',\n",
       " 'snagit',\n",
       " 'amo',\n",
       " 'ahahaha',\n",
       " 'twitcam',\n",
       " 'hashtag',\n",
       " 'rookiemistakes',\n",
       " 'baaahaaa',\n",
       " 'owls',\n",
       " 'fcat',\n",
       " 'arlene',\n",
       " 'oxoxox',\n",
       " 'muaaa',\n",
       " 'twanna',\n",
       " 'violets',\n",
       " 'youtube',\n",
       " 'knowthat',\n",
       " 'earthday',\n",
       " 'stonernation',\n",
       " 'ekk',\n",
       " 'braves',\n",
       " '9-3',\n",
       " 'mets',\n",
       " 'haaa',\n",
       " \"direction's\",\n",
       " '2013',\n",
       " 'promotes',\n",
       " 'tunes',\n",
       " 'bunches',\n",
       " 'iloveyouu',\n",
       " 'mytime',\n",
       " 'cewe',\n",
       " 'bangor',\n",
       " 'nepa',\n",
       " 'erm',\n",
       " 'cheryl',\n",
       " 'jen',\n",
       " 'tweetinglyricslykagangsta',\n",
       " 'voxbox',\n",
       " 'make-up',\n",
       " 'goodies',\n",
       " 'yayyy',\n",
       " 'seeexxy',\n",
       " 'cantwait',\n",
       " 'its420',\n",
       " 'finallyyouadmitit',\n",
       " 'tml',\n",
       " 'racks',\n",
       " 'grades',\n",
       " 'bana',\n",
       " 'sijazoea',\n",
       " 'android',\n",
       " 'bado',\n",
       " 'teamdabr',\n",
       " 'tweeting',\n",
       " 'bfftweet',\n",
       " 'hookt',\n",
       " 'dmy',\n",
       " '3bp3',\n",
       " 'father-like',\n",
       " 'hyung',\n",
       " 'complain',\n",
       " 'watercolor',\n",
       " 'pens',\n",
       " 'misses',\n",
       " 'prevailing',\n",
       " '6.30',\n",
       " 'youcangetmajorpointsif',\n",
       " 'pinay',\n",
       " 'boyfriends',\n",
       " 'udh',\n",
       " 'liat',\n",
       " 'aku',\n",
       " 'senyum',\n",
       " '1000',\n",
       " 'suri',\n",
       " 'pshh',\n",
       " 'cakes',\n",
       " 'cocktails',\n",
       " 'nabshow',\n",
       " 'ainn',\n",
       " 'raspado',\n",
       " 'luc',\n",
       " '333',\n",
       " 'tweetiung',\n",
       " 'mybiggestfearis',\n",
       " 'corrr',\n",
       " 'sexaaay',\n",
       " 'naaah',\n",
       " 'vous',\n",
       " 'aime',\n",
       " 'ich',\n",
       " 'euch',\n",
       " 'lieb',\n",
       " 'behappy',\n",
       " 'networking',\n",
       " 'darling',\n",
       " 'socks',\n",
       " 'coolsocks',\n",
       " 'startyourdaywithasmile',\n",
       " 'michala',\n",
       " 'raced',\n",
       " 'fooling',\n",
       " 'niggas',\n",
       " 'chill',\n",
       " 'pshhh',\n",
       " 'hmmm',\n",
       " 'proudest',\n",
       " 'rolly',\n",
       " 'pollys',\n",
       " 'init',\n",
       " 'counter-example',\n",
       " 'jheeeze',\n",
       " 'cuzzy',\n",
       " 'bunjee',\n",
       " 'automatically',\n",
       " 'primaryschoolmemories',\n",
       " 'takers',\n",
       " \"rt'ed\",\n",
       " 'getcha',\n",
       " 'chachi',\n",
       " 'thankyooou',\n",
       " 'tooony',\n",
       " 'loooveyoou',\n",
       " 'soosooo',\n",
       " 'uhmm',\n",
       " 'letshopeforthebest',\n",
       " 'zebby',\n",
       " 'goodnyt',\n",
       " 'naman',\n",
       " 'fayfe',\n",
       " 'cray',\n",
       " 'prolificwriters',\n",
       " 'appreciated',\n",
       " 'jenny_meszaros',\n",
       " 'poom',\n",
       " 'keepers',\n",
       " 'creepers',\n",
       " 'excitated',\n",
       " 'openfollow',\n",
       " 'kpopers',\n",
       " 'fandom',\n",
       " 'flwrs',\n",
       " 'kece',\n",
       " 'payback',\n",
       " 'makeda',\n",
       " 'nigguhs',\n",
       " 'robinho',\n",
       " 'ctfuuu',\n",
       " 'heknowsbest',\n",
       " 'ilovemydaddy',\n",
       " 'ourrelationship',\n",
       " \"gratz's\",\n",
       " 'powerpoints',\n",
       " \"hilliard's\",\n",
       " 'sappy',\n",
       " 'hottie',\n",
       " 'awwwe',\n",
       " 'confi',\n",
       " 'norwich-london',\n",
       " '8.50',\n",
       " 'depending',\n",
       " 'chirping',\n",
       " 'lolrt',\n",
       " 'skype',\n",
       " \"people's\",\n",
       " 'insecurities',\n",
       " 'economists',\n",
       " \"vat's\",\n",
       " 'hst',\n",
       " 'double-double',\n",
       " 'bethlehem',\n",
       " 'bookbagboys',\n",
       " '2032112',\n",
       " 'lovliest',\n",
       " 'singlelife',\n",
       " 'entrenovias',\n",
       " 'gassed',\n",
       " 'chayton',\n",
       " 'lolol',\n",
       " 'hye',\n",
       " 'classmates',\n",
       " 'jiayou',\n",
       " 'twitneighbours',\n",
       " 'stays',\n",
       " 'sub-tweet',\n",
       " 'kush',\n",
       " 'khalifa',\n",
       " 'mixtapes',\n",
       " 'bbcfootball',\n",
       " 'freshly',\n",
       " 'crockpot',\n",
       " 'smiths',\n",
       " 'shhhshhsshhhshut',\n",
       " 'situations',\n",
       " 'ourwholeuniversewasinahotdensestate',\n",
       " 'notified',\n",
       " 'lantaran',\n",
       " 'kar',\n",
       " 'kita',\n",
       " 'mahal',\n",
       " \"dm's\",\n",
       " 'ftsk',\n",
       " 'announced',\n",
       " 'cosmo',\n",
       " '120',\n",
       " 'ridingsolo',\n",
       " 'myjam',\n",
       " '10.00',\n",
       " 'loveshoes',\n",
       " 'selfharm',\n",
       " 'yoder',\n",
       " 'defiantly',\n",
       " 'reimi',\n",
       " 'boobed',\n",
       " 'seeks',\n",
       " 'screaming',\n",
       " 'noholdingbackk',\n",
       " 'whoaaa',\n",
       " 'stepbrothers',\n",
       " '18th',\n",
       " 'kak',\n",
       " 'creeped',\n",
       " 'blogtv',\n",
       " 'loveyou',\n",
       " 'susta',\n",
       " 'myguards',\n",
       " 'cooo',\n",
       " 'goodnightbabylux',\n",
       " 'harrylovesbabylux',\n",
       " 'teamfollowback',\n",
       " 'esque',\n",
       " 'kevae',\n",
       " 'toolay',\n",
       " 'udah',\n",
       " \"c'monnn\",\n",
       " 'benkelly',\n",
       " 'cjs',\n",
       " 'jonatics',\n",
       " 'jobros',\n",
       " 'switzerlandwants1d',\n",
       " 'loos',\n",
       " 'bekasi',\n",
       " 'juni',\n",
       " 'depok',\n",
       " 'wiwit',\n",
       " 'peop',\n",
       " 'craycray',\n",
       " 'houstonforbtrsummertour',\n",
       " 'specialshoutout',\n",
       " 'broadmoor',\n",
       " 'yelling',\n",
       " 'snuggled',\n",
       " 'reallove',\n",
       " 'gorgeuos',\n",
       " 'miranda',\n",
       " 'freezes',\n",
       " 'bisping',\n",
       " 'shiv',\n",
       " 'asda',\n",
       " 'pringles',\n",
       " 'oreos',\n",
       " 'beautifulcreatures',\n",
       " '287',\n",
       " 'frasier',\n",
       " '1,700',\n",
       " 'bites',\n",
       " \"i'ont\",\n",
       " 'kipling',\n",
       " 'deadman',\n",
       " \"sister's\",\n",
       " 'askzacefron',\n",
       " 'sinasabi',\n",
       " 'hollaa',\n",
       " 'hairs',\n",
       " 'uwc',\n",
       " 'awh',\n",
       " 'piling',\n",
       " 'greatmindsthinkalike',\n",
       " 'aahha',\n",
       " 'nipples',\n",
       " 'yurp',\n",
       " 'suvis',\n",
       " 'tweeted',\n",
       " '9am',\n",
       " 'mumford',\n",
       " 'laughs',\n",
       " 'trooping',\n",
       " 'friendship',\n",
       " 'bobbobbob',\n",
       " 'tq32',\n",
       " '81319',\n",
       " 'modelling',\n",
       " 'scouts',\n",
       " 'hirap',\n",
       " 'bumangon',\n",
       " 'umaga',\n",
       " 'marcus',\n",
       " 'sofitel',\n",
       " 'vegas',\n",
       " 'stoner',\n",
       " \"bieb's\",\n",
       " 'cheek',\n",
       " 'wassup',\n",
       " 'sogreat',\n",
       " 'youur',\n",
       " 'gurlll',\n",
       " '--->',\n",
       " '50k',\n",
       " 'teamissa',\n",
       " 'issato50k',\n",
       " 'echt',\n",
       " 'gaaf',\n",
       " 'leuk',\n",
       " 'londoners',\n",
       " 'zayn',\n",
       " 'egoistc',\n",
       " 'mannu',\n",
       " 'shorts',\n",
       " 'vlogging',\n",
       " 'appreciating',\n",
       " 'awee',\n",
       " 'omf',\n",
       " 'palms',\n",
       " 'starworld',\n",
       " 'cousins',\n",
       " 'batesburg',\n",
       " 'nevermind',\n",
       " 'budddie',\n",
       " 'jodi',\n",
       " \"picoult's\",\n",
       " 'co-own',\n",
       " 'airen',\n",
       " 'mercies',\n",
       " \"lil'sister\",\n",
       " 'saaayinggg',\n",
       " 'akala',\n",
       " 'ngayon',\n",
       " 'peaches',\n",
       " 'naa',\n",
       " 'updating',\n",
       " 'interviews',\n",
       " 'journey',\n",
       " 'educated',\n",
       " 'nigha',\n",
       " 'heatnation',\n",
       " 'mcdeaner',\n",
       " 'stendan',\n",
       " 'mcdean',\n",
       " 'oopsie',\n",
       " 'jls',\n",
       " 'mam',\n",
       " 'reblog',\n",
       " 'matilda',\n",
       " 'meteen',\n",
       " 'drinken',\n",
       " 'goodmorningg',\n",
       " 'chachii',\n",
       " 'relise',\n",
       " 'trung',\n",
       " 'redding',\n",
       " 'fairdoos',\n",
       " 'etc',\n",
       " 'brainier',\n",
       " 'wrinkly',\n",
       " \"zuby's\",\n",
       " 'thingsenglishmumssay',\n",
       " 'thingsafricanmumssay',\n",
       " 'cards',\n",
       " 'sharpe',\n",
       " 'myyy',\n",
       " 'zefron',\n",
       " 'varsity',\n",
       " 'followpenshoppeallstars',\n",
       " '262',\n",
       " 'supaaa',\n",
       " 'shotguns',\n",
       " '6.8',\n",
       " '9:11',\n",
       " 'swagged',\n",
       " 'putittouse',\n",
       " 'striptease',\n",
       " 'pei',\n",
       " 'peislanders',\n",
       " 'sath',\n",
       " 'gya',\n",
       " 'soowieee',\n",
       " 'thisgirl',\n",
       " 'longlife',\n",
       " 'traktir',\n",
       " 'cuuh',\n",
       " 'lionking',\n",
       " 'ameen',\n",
       " 'bruhhh',\n",
       " 'marquilla',\n",
       " 'uncles',\n",
       " 'cantsayno',\n",
       " '10am',\n",
       " 'nashta',\n",
       " 'alpen',\n",
       " 'theres',\n",
       " \"jimbo's\",\n",
       " 'x-kayya',\n",
       " 'best-in-class',\n",
       " 'understands',\n",
       " 'boiii',\n",
       " 'designers',\n",
       " 'francisco',\n",
       " 'fakinnn',\n",
       " 'brilliantly',\n",
       " 'mommas',\n",
       " 'hacienda',\n",
       " 'leii',\n",
       " 'hao',\n",
       " 'hehh',\n",
       " 'manz',\n",
       " 'aah',\n",
       " 'whizz',\n",
       " 'pffft',\n",
       " 'smartest',\n",
       " '8-10',\n",
       " '60-100',\n",
       " 'okaaayyy',\n",
       " 'aly',\n",
       " 'waylon',\n",
       " 'easy',\n",
       " 'structures',\n",
       " 'cheltenham',\n",
       " 'yates',\n",
       " 'squad',\n",
       " 'southend',\n",
       " 'matiliku',\n",
       " 'confirms',\n",
       " 'muthokoi',\n",
       " 'hacked',\n",
       " 'teenagers',\n",
       " 'relationships',\n",
       " 'colton',\n",
       " 'ughh',\n",
       " 'devlishly',\n",
       " 'yayayayaya',\n",
       " 'atx',\n",
       " 'movvve',\n",
       " 'yeahhhmannn',\n",
       " 'bridgette',\n",
       " 'pinoy',\n",
       " 'kasunod',\n",
       " 'hahahahha',\n",
       " 'anita',\n",
       " 'gigmemories',\n",
       " 'ripping',\n",
       " 'jays',\n",
       " 'campuran',\n",
       " 'bhsa',\n",
       " 'nya',\n",
       " 'arigato',\n",
       " 'begun',\n",
       " 'thanyou',\n",
       " 'sirens',\n",
       " 'peeing',\n",
       " 'nmn',\n",
       " 'kahit',\n",
       " 'malayo',\n",
       " 'playdate',\n",
       " 'justgottafindadate',\n",
       " 'dayoff',\n",
       " 'dongyaa',\n",
       " 'abdc',\n",
       " '6:38',\n",
       " 'tacos',\n",
       " 'xx17',\n",
       " 'grits',\n",
       " 'teamlesbian',\n",
       " 'tesco',\n",
       " 'pizzas',\n",
       " 'antquan',\n",
       " '112',\n",
       " 'caredd',\n",
       " 'sheens',\n",
       " 'devonta',\n",
       " 'ashanti',\n",
       " \"t'kay\",\n",
       " 'hosgeldin',\n",
       " 'sekerim',\n",
       " 'yesshhh.it',\n",
       " 'shawdy',\n",
       " 'reallybringsouttheugliness',\n",
       " 'objectives',\n",
       " 'increases',\n",
       " 'scores',\n",
       " 'dramatically',\n",
       " 'meooow',\n",
       " 'neil',\n",
       " 'irespectfemales',\n",
       " 'dumbest',\n",
       " 'whore-ist',\n",
       " 'nikefuel',\n",
       " \"rachel's\",\n",
       " 'toosweetandinnocent',\n",
       " 'hearted',\n",
       " 'prayforsun',\n",
       " 'wroxton',\n",
       " 'richmondproblems',\n",
       " 'cassy',\n",
       " 'besho',\n",
       " 'shoutouy',\n",
       " 'luigi',\n",
       " 'xoxoxoxo',\n",
       " 'travelsafelysnuggles',\n",
       " 'goodluck',\n",
       " 'korra',\n",
       " '25th',\n",
       " 'mowry',\n",
       " 'realizes',\n",
       " 'tanx',\n",
       " 'papi',\n",
       " 'howgoodcouldihavebeenif',\n",
       " 'howgreatimgonnabebecause',\n",
       " 'wornout',\n",
       " ...]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "cactus\n",
      "goose\n",
      "rock\n",
      "python\n",
      "good\n",
      "best\n",
      "run\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_lem = [lemmatizer.lemmatize(w) for w in unknown]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dict = [w for w in unknown_lem if w in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8961, 512816)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(in_dict), len(unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.58061302809556"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([tkn_counter[w] for w in in_dict])*100/sum(tkn_counter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.160163984556576"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([tkn_counter[w] for w in set(unknown_lem)- set(in_dict)])*100/sum(tkn_counter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['horanywhores',\n",
       " 'nicolaus',\n",
       " 'deactived',\n",
       " 'rufford',\n",
       " 'substantialerror',\n",
       " 'tiny.lol',\n",
       " 'hamat',\n",
       " 'sluttiness',\n",
       " 'files-y',\n",
       " 'crnp',\n",
       " '33154',\n",
       " '-6728-090',\n",
       " 'teheee',\n",
       " 'dontwanttogobacktojail',\n",
       " 'twill',\n",
       " 'kaleidotile',\n",
       " 't-bevel',\n",
       " 'crazybfprobz',\n",
       " 'afram',\n",
       " 'w8t',\n",
       " 'mind--how',\n",
       " 'nxgga',\n",
       " 'kyodai',\n",
       " 'wanttocry',\n",
       " 'luvya',\n",
       " 'bnch',\n",
       " \"merrell's\",\n",
       " 'g33k',\n",
       " 'time.good',\n",
       " 'anydoctorshere',\n",
       " \"eyebrow's\",\n",
       " 'yesweregay',\n",
       " 'machu',\n",
       " 'for.work',\n",
       " '72.5',\n",
       " 'griffs',\n",
       " 'mydaywillcome',\n",
       " 'pre-fo',\n",
       " 'tewmorrow',\n",
       " 'lilliput',\n",
       " 'hammermill',\n",
       " 'utero',\n",
       " 'sescelduled',\n",
       " 'gotcho',\n",
       " 'moltke',\n",
       " 'clendenen',\n",
       " \"kob's\",\n",
       " 'fa1772',\n",
       " 'festo',\n",
       " 'responsi',\n",
       " 'lazed',\n",
       " 'hair-do',\n",
       " 'bagong',\n",
       " 'p-diddy',\n",
       " 'cameronresign',\n",
       " 'harry_jeffery',\n",
       " 'teamplapla',\n",
       " 'madryd',\n",
       " 'everysingletime',\n",
       " 'maimed',\n",
       " 'ineeeht',\n",
       " 'ms7580',\n",
       " 'carterton',\n",
       " 'jewoisdktr',\n",
       " 'gunne',\n",
       " \"reusch's\",\n",
       " 'ts300',\n",
       " 'ilovewhen',\n",
       " 'screenthis',\n",
       " 'rarerthanhensteeth',\n",
       " 'allownig',\n",
       " 'tarnecky',\n",
       " 'struggglin',\n",
       " 'eyebolt',\n",
       " 'missyouprettyhead',\n",
       " 'harrystyleschatuplines',\n",
       " 'w-jam',\n",
       " 'kickingass',\n",
       " '31sts',\n",
       " 'ibhm',\n",
       " 'theyrejustsocute',\n",
       " 'dty',\n",
       " 'c6656a',\n",
       " 'determining',\n",
       " 'jelebers',\n",
       " 'doyles',\n",
       " 'mouat',\n",
       " \"wahoo's\",\n",
       " 'riiqht',\n",
       " 'catdaddy',\n",
       " '100mi',\n",
       " 'feet.bounce',\n",
       " 'heydongho',\n",
       " 'wiwww',\n",
       " 'stagearts',\n",
       " \"don't\",\n",
       " 'nostalgyc',\n",
       " 'liaaamm',\n",
       " 'tryingtobepositive',\n",
       " 'mis-matched',\n",
       " 'notgonnalie',\n",
       " 'iloveniallhoran33.tumblr.com/',\n",
       " 'libbi',\n",
       " 'apoois',\n",
       " 'nj-j',\n",
       " '4:25',\n",
       " 'itshotitburns',\n",
       " '900bt',\n",
       " 'u-n-l-u-c-k-y-gi-r-l',\n",
       " 'nt258',\n",
       " 'whrt',\n",
       " 'tomortow',\n",
       " '1millions',\n",
       " 'arma',\n",
       " '21millionstrong',\n",
       " 'n1700w',\n",
       " 'dampens',\n",
       " 'it.congrats',\n",
       " 'muwhaha',\n",
       " \"katzen's\",\n",
       " 'robopocalypse',\n",
       " 'starcke',\n",
       " 'sneakymofo',\n",
       " 'rosella',\n",
       " 'ac-fpxt_rev',\n",
       " 'ekltvn',\n",
       " 'tealove',\n",
       " '91725',\n",
       " 'pblchat',\n",
       " 'superworm',\n",
       " 'infobdg',\n",
       " 'fridayitis',\n",
       " 'baaccckkk',\n",
       " '5707519',\n",
       " 'biograp',\n",
       " 'regect',\n",
       " 'scrotes',\n",
       " 'andrewliversalt',\n",
       " 'inisa-isa',\n",
       " 'holidayfootball',\n",
       " 'benarkan',\n",
       " 'asleep.rt',\n",
       " 'ldrp',\n",
       " 'waupun',\n",
       " 'deckdate',\n",
       " 'poooft',\n",
       " 'kinnara',\n",
       " '900776',\n",
       " 'me.hehe',\n",
       " 'houseworkly',\n",
       " \"how've\",\n",
       " 'pluie',\n",
       " 'yorkshire-harrogate',\n",
       " 'acrylicfmvss',\n",
       " 'p-s',\n",
       " 'jensen-healey',\n",
       " 'covssi',\n",
       " \"of-freakin'-course\",\n",
       " '21x25',\n",
       " 'aguilara',\n",
       " 't500',\n",
       " 'funatic',\n",
       " 'tooodays',\n",
       " 'keyell',\n",
       " 'alltel',\n",
       " 'spngebob',\n",
       " 'whw',\n",
       " 'scary-looking',\n",
       " 'a220',\n",
       " \"polanski's\",\n",
       " 'subsidia',\n",
       " 'sommie',\n",
       " 'babaaa',\n",
       " 'mv276',\n",
       " 'jkjwrbhba',\n",
       " 'dublin-based',\n",
       " 'diskstation',\n",
       " 'niak',\n",
       " 'mohahahahahahahahahahahhahahahahahhahaha',\n",
       " 'zuvo',\n",
       " 'outty',\n",
       " 'brightvue',\n",
       " 'book-and-audio',\n",
       " 'lolsz',\n",
       " 'plantingitandlisteningit',\n",
       " 'mullingar',\n",
       " 'slerpytweet',\n",
       " 'fonseca',\n",
       " 'deserting',\n",
       " 'upanddown',\n",
       " 'nyummmyy',\n",
       " \"carlile's\",\n",
       " 'nuneaton',\n",
       " 'beertime',\n",
       " 'nonporous',\n",
       " 'nowwhowillistalk',\n",
       " '9:22',\n",
       " '1dlikebigbums',\n",
       " 'jensem',\n",
       " 'ngmall',\n",
       " 'longlasssttt',\n",
       " 'evenwhenyoucheat',\n",
       " 'snazzay',\n",
       " 'cuteer',\n",
       " '-9/11',\n",
       " 'mytruefriend',\n",
       " \"mgmt's\",\n",
       " 'rambo',\n",
       " \"simba's\",\n",
       " 'devotes',\n",
       " 'booacne',\n",
       " 'fangaz',\n",
       " 'v40315',\n",
       " 'ormus',\n",
       " 'maka.graduate',\n",
       " 'schmelling',\n",
       " 'np-pratice',\n",
       " 'c004',\n",
       " 'yeshomo',\n",
       " '5506',\n",
       " 'buaji',\n",
       " 'bobb',\n",
       " 'brighterminds',\n",
       " 'lifesbestmoments',\n",
       " 'bimby',\n",
       " 'knpa',\n",
       " 'pagum',\n",
       " 'cardi',\n",
       " \"naomi's\",\n",
       " 'gisele',\n",
       " 'ohmygosh',\n",
       " 'polywell',\n",
       " 'dv5097ea',\n",
       " 'tthotrightnow',\n",
       " 'emutm',\n",
       " 'awkwardmomentwhen',\n",
       " \"marietta's\",\n",
       " \"talky's\",\n",
       " 'tittin',\n",
       " 'discessed',\n",
       " 'levant--a',\n",
       " 'strangaa',\n",
       " 'twitterlesspurps',\n",
       " 'seagates',\n",
       " '3337',\n",
       " 'seahawks',\n",
       " 'syma',\n",
       " 'seposen',\n",
       " 'shabigglyante',\n",
       " 'miri',\n",
       " 'topik',\n",
       " '12pos',\n",
       " '289',\n",
       " 'intinya',\n",
       " 'lapyuu',\n",
       " '1030em',\n",
       " 'mirrraaa',\n",
       " 'baskeville',\n",
       " '4410n',\n",
       " 'sd376',\n",
       " 'chaoz',\n",
       " '2mraa',\n",
       " 'busyness',\n",
       " 'a5lso',\n",
       " 'melawno',\n",
       " 'worththewait',\n",
       " 'swordhowl',\n",
       " 'nett',\n",
       " 'moochelle',\n",
       " 'nanay',\n",
       " '47506',\n",
       " 'shifnal',\n",
       " \"butty's\",\n",
       " 'aao',\n",
       " 'daun',\n",
       " 'fthat',\n",
       " 'aegyptische',\n",
       " 'zipbin',\n",
       " 'shernei',\n",
       " 'wetland',\n",
       " 'stagemaster',\n",
       " 'eight-year-old',\n",
       " 'lipstains',\n",
       " 'enamel-gilty',\n",
       " 'tamoniee',\n",
       " 'creuset',\n",
       " 'musiqueplus',\n",
       " 'beautifi',\n",
       " 'icon-fmcl',\n",
       " 'gonzaga',\n",
       " 'shedidntknow',\n",
       " 'wifeyy',\n",
       " 'apeee',\n",
       " 'aftersun',\n",
       " 'mytheory',\n",
       " '2603866',\n",
       " '11.17',\n",
       " '4.2012',\n",
       " \"y'zeit\",\n",
       " 'dummmbyyy',\n",
       " '7603',\n",
       " 'ocake',\n",
       " 'deltadream',\n",
       " 'malaoholic',\n",
       " \"rapper's\",\n",
       " 'boyer',\n",
       " 'bestseller--the',\n",
       " '800l',\n",
       " 'ktmu',\n",
       " 'ee3',\n",
       " '6905',\n",
       " 'loni',\n",
       " 'cb2s950',\n",
       " 'lesmiserable',\n",
       " 'fourtet',\n",
       " '18kw',\n",
       " 'muthafugggaaas',\n",
       " 'chuckiee',\n",
       " '2:05',\n",
       " 'iamsoclumsy',\n",
       " 'twuggar',\n",
       " 'sblm',\n",
       " 'frieldlys',\n",
       " 'thronesa',\n",
       " 'melua',\n",
       " 'g-stop',\n",
       " 'el-shater',\n",
       " 'bizjournals',\n",
       " 'ariesfajar',\n",
       " 'ph520',\n",
       " 'hd284',\n",
       " 'hardday',\n",
       " 'happpeenss',\n",
       " 'nagseslos',\n",
       " 'ihahahahahahahahah',\n",
       " 'nfta',\n",
       " 'overwrites',\n",
       " 'llvlc',\n",
       " 'namedd',\n",
       " \"the'll\",\n",
       " 'd50065',\n",
       " 'hogha',\n",
       " 'am3696',\n",
       " 'vevovideos',\n",
       " 'femmed-out',\n",
       " 'tickly',\n",
       " 'ilovemyparents',\n",
       " 'promnight2012',\n",
       " 'mimada',\n",
       " 'harshheck',\n",
       " 'gusini',\n",
       " 'alrightalrightalriight',\n",
       " 'mackin',\n",
       " 'bruckshot',\n",
       " 'imattractedtothat',\n",
       " 'recockulous',\n",
       " 'everywherrreee',\n",
       " '285s2',\n",
       " 'happest',\n",
       " 'pagggi',\n",
       " 'stopatnothing',\n",
       " 'unstannn',\n",
       " 'erte',\n",
       " 'redcar',\n",
       " 'terkadang',\n",
       " \"thhat's\",\n",
       " 'bestpartoffallterm',\n",
       " 'broek',\n",
       " 'nayati',\n",
       " 'ennie',\n",
       " 'gorton',\n",
       " 'fa-mo-us',\n",
       " 'poly-vinyl',\n",
       " 'caseypower',\n",
       " 'maxl',\n",
       " 'getjessicahammondsigned',\n",
       " 'saltburn',\n",
       " 'farcus',\n",
       " 'raisedthemwell',\n",
       " 'bskyb',\n",
       " 'sda',\n",
       " 'sabriel',\n",
       " 'ihateweekdays',\n",
       " 'at-easy',\n",
       " 'majorwak',\n",
       " 'brendley',\n",
       " 'tipp-exing',\n",
       " 'pre-seasoned',\n",
       " 'neversing',\n",
       " 'measures---if',\n",
       " 'bodymindcore',\n",
       " 'mcdeezies',\n",
       " 'hhehhh',\n",
       " 'digestables',\n",
       " 'bobok',\n",
       " 'lb3eed',\n",
       " 'raonic',\n",
       " 'sadfuckentweet',\n",
       " '42330',\n",
       " 'oktroll',\n",
       " 'maskeena',\n",
       " 'trance-formation',\n",
       " 'hairsruined',\n",
       " 'lubs',\n",
       " 'beeellliiivvveee',\n",
       " 'nks',\n",
       " \"g'wan\",\n",
       " \"arkell's\",\n",
       " 'oda',\n",
       " 'tidung',\n",
       " 'sod-kie',\n",
       " 'gtaproblems',\n",
       " '7bk',\n",
       " 'roky',\n",
       " 'procrastinationsucks',\n",
       " 'capek',\n",
       " '-7-13',\n",
       " '11:51',\n",
       " 'gryffindors',\n",
       " '256-40-',\n",
       " 'codey',\n",
       " 'dikhead',\n",
       " '2680-20',\n",
       " 'jihooo',\n",
       " 'mrsbrownsboys',\n",
       " 'jimmie',\n",
       " 'kmu',\n",
       " 'carefreemotive',\n",
       " 'futuremoviemommy',\n",
       " '10kz',\n",
       " 'nabigla',\n",
       " 'mafrood',\n",
       " 'glennn',\n",
       " 'meeking',\n",
       " 'nonelective',\n",
       " 'ti-vo',\n",
       " 'teamnaturalblonde',\n",
       " 'aaich',\n",
       " 'lpsa',\n",
       " 'nenadovia',\n",
       " 'sehingga',\n",
       " '3ios',\n",
       " 'cubaaa',\n",
       " 'singaporelahh',\n",
       " 'untying',\n",
       " 'everythingissound',\n",
       " 'mengorat',\n",
       " \"l'acadie\",\n",
       " 'emtc',\n",
       " 'aytho',\n",
       " 'skeppy',\n",
       " 'funnnytimes',\n",
       " 'indiocumentado',\n",
       " 'ninda',\n",
       " '82015',\n",
       " 'bethhh',\n",
       " 'patrizia',\n",
       " 'eida',\n",
       " 'infoquake',\n",
       " 'pricy',\n",
       " 'typicalscare',\n",
       " 'pandora',\n",
       " 'teigs',\n",
       " 'mega-resistance',\n",
       " 'winooskis',\n",
       " 'archeologia',\n",
       " 'beigeee',\n",
       " 'didnt.know',\n",
       " 'july-drake',\n",
       " 'snap-cap',\n",
       " 'sensa',\n",
       " 'race-inspi',\n",
       " 'buafl',\n",
       " 'coodyy',\n",
       " 'funnienst',\n",
       " 'dimensia',\n",
       " 'taute',\n",
       " 'sogoneent',\n",
       " 'perrymood',\n",
       " 'p9ox',\n",
       " 'quadbloggng',\n",
       " 'puccinos',\n",
       " '2cm',\n",
       " 'milcreek',\n",
       " 'reminisced',\n",
       " 'efes',\n",
       " '091443u',\n",
       " 'spirit-led',\n",
       " '530pm',\n",
       " 'getsubmitting',\n",
       " 'u.hehe',\n",
       " 'tagsa',\n",
       " 'hollidaysburg',\n",
       " 'forlag',\n",
       " 'sloim',\n",
       " 'caira',\n",
       " 'co-d',\n",
       " 'ker',\n",
       " 'improove',\n",
       " 'maxsight',\n",
       " 'nyceee',\n",
       " 'shamira',\n",
       " 'aizzat',\n",
       " 'vice-presidential',\n",
       " 'aaugh',\n",
       " 'volujica',\n",
       " 'wanmkkk',\n",
       " '46fx',\n",
       " 'girfiends',\n",
       " 'cher-yl',\n",
       " 'djfdhddhgchfghgfhhdhjgcdghdfjfdhjfvjdfjyfhgdggfhjfhhhggg',\n",
       " 'urk',\n",
       " \"gatti'd\",\n",
       " 'bebehhh',\n",
       " 'authoritive',\n",
       " 'misleader',\n",
       " '32x20x61',\n",
       " 'cp220',\n",
       " '25vtp',\n",
       " 'newbiee',\n",
       " 'semalem',\n",
       " 'layedd',\n",
       " 'monn',\n",
       " 'saturdaynightplaylist',\n",
       " '6211',\n",
       " 'yanyan',\n",
       " 'freshink',\n",
       " 'raisibe_m',\n",
       " 'adese',\n",
       " 'yury',\n",
       " 'dayne',\n",
       " '3ffx',\n",
       " 'lifeofaslut',\n",
       " 'onlytwominutesaway',\n",
       " 'sillyamber',\n",
       " 'shaaari',\n",
       " \"bubble's\",\n",
       " 'vote4jay',\n",
       " 'h4nd',\n",
       " 'demian',\n",
       " 'franchiseplease',\n",
       " 'newsflesh',\n",
       " 'diyo',\n",
       " 'brudder',\n",
       " \"pope's\",\n",
       " 'bestmomever',\n",
       " 'unholiness',\n",
       " 'lostener',\n",
       " \"reisil's\",\n",
       " 'n222463',\n",
       " 'mullinger',\n",
       " 'thingsillmissaboutmes',\n",
       " 'e34',\n",
       " 'dermisil',\n",
       " 'mehfil',\n",
       " 'amiie',\n",
       " 'faaacking',\n",
       " 'gyalies',\n",
       " 'haezar',\n",
       " 'nosmiles',\n",
       " 'uglyweather',\n",
       " 'nesquick',\n",
       " 'unnir',\n",
       " 'know-howjewelry',\n",
       " 'unplease',\n",
       " 'bring1dtospain',\n",
       " 'teamdavis',\n",
       " 'lambily',\n",
       " 'kronk',\n",
       " 'jerret',\n",
       " 'randomhashtag',\n",
       " 'prayforhim',\n",
       " 'famette',\n",
       " \"kerr's\",\n",
       " 'thanksgirls',\n",
       " 'shantanice',\n",
       " 'deehorlaar',\n",
       " 'leyyowww',\n",
       " 'skinsteeth',\n",
       " '91a',\n",
       " 'rabbena',\n",
       " 'jmraz',\n",
       " 's-biners',\n",
       " 'oishhh',\n",
       " 'huahahha',\n",
       " 'paxar',\n",
       " 'markzuckerberg',\n",
       " 'growinguptooofast',\n",
       " 'churchtonight',\n",
       " 'traveltrax',\n",
       " 'f-br',\n",
       " '19thanniversary',\n",
       " 'cci',\n",
       " 'bisbol',\n",
       " 'wowowoww',\n",
       " \"n'put\",\n",
       " 'rv279',\n",
       " 'stratz',\n",
       " 'overwhel',\n",
       " 'ohwellitstomorrow',\n",
       " 'rusta',\n",
       " 'md1',\n",
       " 'panjiva',\n",
       " \"xavi's\",\n",
       " '3.9370',\n",
       " 'ibroprufen',\n",
       " 'nightowl',\n",
       " 'mclilykinsretirement',\n",
       " 'noteamtonight',\n",
       " 'jogin',\n",
       " 'tiffanyarianataylorjustin',\n",
       " 'centrelink',\n",
       " 'ckit',\n",
       " 'at9943',\n",
       " 'ambushed',\n",
       " 'customskiller',\n",
       " 'neutralhazer',\n",
       " 'gc1515mfra1',\n",
       " 'cs1sw',\n",
       " 'lveyou',\n",
       " 'shirriff',\n",
       " 'caeden',\n",
       " 'sentens',\n",
       " 'iificanthaveyou',\n",
       " 'gigistaysgay',\n",
       " 'viso',\n",
       " 'ssshite',\n",
       " 'brilliantcolor',\n",
       " 'photona',\n",
       " 'kumand',\n",
       " 'zipfy',\n",
       " 'sangye',\n",
       " 'bljr',\n",
       " 'lenguh',\n",
       " 'agsgdffkjgfhfsfadhfjgjjgfhdgsgsgsaahdgfgfagsdfdffhfkssaggrfgdshghxfd',\n",
       " \"condon's\",\n",
       " 'ozza',\n",
       " 'twe',\n",
       " 'gagew',\n",
       " 'pinproblems',\n",
       " '6-1',\n",
       " 'nazarian',\n",
       " 'computatio',\n",
       " '615-587-6360',\n",
       " 'othawise',\n",
       " 'amazaballs',\n",
       " 'ultraworld',\n",
       " 'b-mx',\n",
       " 'sheerany',\n",
       " \"hershey's\",\n",
       " 'jabriel',\n",
       " 'daschle',\n",
       " '92143',\n",
       " '110pt',\n",
       " 'mamou',\n",
       " 'furiou',\n",
       " 'pickling',\n",
       " 'summerythis',\n",
       " 'thephonehis',\n",
       " 'bucket-multi',\n",
       " 'vinita',\n",
       " 'actorchild',\n",
       " 'earnshaws',\n",
       " 'lagassie',\n",
       " 'cougartweet',\n",
       " 'xcodeband',\n",
       " 'chipboard',\n",
       " 'xavn',\n",
       " 'city-state',\n",
       " 'airich',\n",
       " 'conservatorship',\n",
       " 'itlldonextyear',\n",
       " '77-189',\n",
       " 'sexysurfhair',\n",
       " 'hyyype',\n",
       " 'gottastudyhard',\n",
       " 'thehost',\n",
       " 'e71',\n",
       " 'inter-m',\n",
       " 'oneall',\n",
       " 'catchmaster',\n",
       " \"steel's\",\n",
       " 'stpetersburg',\n",
       " '001127-00',\n",
       " '117',\n",
       " 'luhmangintan',\n",
       " '703-864-0888',\n",
       " '-570-76901',\n",
       " 'daraaa',\n",
       " 'borden',\n",
       " 'jennie',\n",
       " 'barbarabowl',\n",
       " 'kuvlesky',\n",
       " 'shunny',\n",
       " 'omgawd',\n",
       " 'ohhhyehhh',\n",
       " 'sarah.makes',\n",
       " 'transparenz',\n",
       " 'hadapi',\n",
       " 'dontbeadraggg',\n",
       " 'pickedtherightone',\n",
       " 'beatphillyu',\n",
       " 'aplang',\n",
       " 'soflippingannoyed',\n",
       " 'pandaaas',\n",
       " 'madla',\n",
       " 'swedishhousemafia',\n",
       " 'favsongofalltime',\n",
       " 'racikan',\n",
       " '2865',\n",
       " 'noprimetime',\n",
       " '6,629',\n",
       " 'mantauk',\n",
       " 'preboard',\n",
       " 'sycafe',\n",
       " 'mbird',\n",
       " 'ineverseeanythingcool',\n",
       " 'driveintribeca',\n",
       " 'daany',\n",
       " 'thirl',\n",
       " 'aprilx',\n",
       " 'veratti',\n",
       " 'denda',\n",
       " 'reptar',\n",
       " 'everthingisgettingtome',\n",
       " 'nonspringfloor',\n",
       " 'lyset',\n",
       " 'rybka',\n",
       " 'catalyzed',\n",
       " 'shereka',\n",
       " \"know--wasn't\",\n",
       " 'gowascension',\n",
       " 'rapelang',\n",
       " 'icecam',\n",
       " 'pro-best',\n",
       " 'twitter.2012-04-28-05.lzo.cleaned',\n",
       " 'acommodationfail',\n",
       " 'clappping',\n",
       " 'poodie',\n",
       " 'fmlproblems',\n",
       " 'procrastinates',\n",
       " 'braiden',\n",
       " 'beforework',\n",
       " 'adultwork',\n",
       " 'bater',\n",
       " 'notafanoflackofsleep',\n",
       " 'kansai',\n",
       " 'morale--a',\n",
       " '7ob',\n",
       " 'wikied',\n",
       " 'kuiyp',\n",
       " 'atlaantic',\n",
       " 'myfavoritedayoftheweek',\n",
       " 't49750',\n",
       " 'offtolab',\n",
       " 'cheerupbuttercup',\n",
       " 'tramadol',\n",
       " '(9780321414',\n",
       " 'fromday1',\n",
       " 'klink',\n",
       " 'bissaaa',\n",
       " 'bz48co',\n",
       " \"henna's\",\n",
       " 'requesttt',\n",
       " 'iamtope',\n",
       " 'bombgirls',\n",
       " 'v3800n',\n",
       " 'shirlana',\n",
       " 'ob403',\n",
       " 'kingsville',\n",
       " 'l-men',\n",
       " 'championshipforvilla',\n",
       " 'dbc',\n",
       " 'jaajajjajjajaja',\n",
       " 'mupeeeng',\n",
       " 'nerdvana',\n",
       " 'temburong',\n",
       " 'downloadable',\n",
       " 'rmp',\n",
       " 'cartoonito',\n",
       " 'assassins2012',\n",
       " 'specta',\n",
       " 'chinkyeyes',\n",
       " 'tamou',\n",
       " 'ooouuussshhh',\n",
       " 'mascarenhas',\n",
       " 'shoabs',\n",
       " 'singingmywaytosleep',\n",
       " 'magnanti',\n",
       " 'nelco',\n",
       " 'lvndr',\n",
       " '13f',\n",
       " 'fortay',\n",
       " 'oalah',\n",
       " 'watte',\n",
       " 'proudofnole',\n",
       " 'homedawgg',\n",
       " 'tridesign',\n",
       " 'lu-c',\n",
       " \"wizkid's\",\n",
       " 'teamfallingapart',\n",
       " 'bea_creamz',\n",
       " 'mandurah',\n",
       " '5eeeft',\n",
       " '0.90',\n",
       " 'sailormoon',\n",
       " 'ilovemychoirfamily',\n",
       " 'bahria',\n",
       " '29100',\n",
       " 'whyyyme',\n",
       " 'okiedokes',\n",
       " \"nba's\",\n",
       " 'construction-move',\n",
       " 'twdutch',\n",
       " 'averybody',\n",
       " 'morrgan',\n",
       " 'witbooi',\n",
       " 'hischoolprobs',\n",
       " 'yeochins',\n",
       " 'weekendpalooza',\n",
       " 'notsick',\n",
       " 'niallofficial',\n",
       " 'mybitches',\n",
       " 'primatology',\n",
       " 'mr.tightpants',\n",
       " 'ellathavante',\n",
       " 'agbanirt',\n",
       " 'youthe',\n",
       " 'dothere',\n",
       " 'friendsaddicts',\n",
       " 'sleep-n-ledge',\n",
       " 'replacesongswith1d',\n",
       " 'ednita',\n",
       " 'firstworldpains',\n",
       " '31493',\n",
       " 'taggiasca',\n",
       " 'goalfor4',\n",
       " '4meals',\n",
       " 'x-alp',\n",
       " 'otapiapia',\n",
       " 'stupidsunday',\n",
       " 'replaying',\n",
       " 'reedly',\n",
       " 'miao-miao',\n",
       " 'nicoo',\n",
       " 'chitchating',\n",
       " \"elvira's\",\n",
       " '0990-1',\n",
       " 'non-consensual',\n",
       " 'uurg',\n",
       " 'knee-high',\n",
       " '234554',\n",
       " 'wobbie',\n",
       " 'butewschool',\n",
       " '240-243',\n",
       " 'absolutelyterrified',\n",
       " 'vf0280',\n",
       " 'ihatedoug',\n",
       " 'su3000rtxr3u',\n",
       " 'desti',\n",
       " 'lish',\n",
       " 'lazier',\n",
       " '1829-1898',\n",
       " 'kessler',\n",
       " '388p',\n",
       " 'idontknoweverything',\n",
       " 'fonebill',\n",
       " 'e4310',\n",
       " '1.758-',\n",
       " 'watchoutwegotabadassoverhere',\n",
       " '6432cf',\n",
       " '22.05',\n",
       " 'difficut',\n",
       " 'melcher',\n",
       " '605374',\n",
       " 'nehhh',\n",
       " '6000k',\n",
       " 'yadong',\n",
       " 'thingsthatreallymakesmeangry',\n",
       " 'angnayo-ke',\n",
       " '-4:20',\n",
       " 'armstong',\n",
       " 'shaquntanella',\n",
       " 'cuete',\n",
       " 'wildest',\n",
       " 'jelgava',\n",
       " 'youreawesome',\n",
       " 'notaheadfucker',\n",
       " 'flowmeter',\n",
       " 'tkp',\n",
       " 'jealousofakoala',\n",
       " '9200th',\n",
       " \"coltrane's\",\n",
       " 'livelikethelorax',\n",
       " 'boundingtime',\n",
       " 'feelingshitagain',\n",
       " 'match.pop',\n",
       " 'infctd',\n",
       " 'youthebest',\n",
       " 'wainlins',\n",
       " 'w225332',\n",
       " 'stenographic',\n",
       " 'ripkanersmullet',\n",
       " 'dorang',\n",
       " 'the.next',\n",
       " 'lorenza',\n",
       " 'cantwaittilltheygetbig',\n",
       " 'grafpendant',\n",
       " '4x0',\n",
       " 'hatethechase',\n",
       " 'ex490',\n",
       " 'bootycallworkout',\n",
       " 'survivalmode',\n",
       " 'c752',\n",
       " 'datra',\n",
       " 'harish',\n",
       " 'instabeauty',\n",
       " 'dm991',\n",
       " 'ratprobz',\n",
       " 'pusaka',\n",
       " 'nam-upgd',\n",
       " 'liza',\n",
       " 'montagues',\n",
       " 'ayi.its',\n",
       " 'lipservice2',\n",
       " 'matryoshka',\n",
       " 'geeets',\n",
       " 'nampa',\n",
       " 'kofar',\n",
       " 'mikaelas',\n",
       " 'oxfordd',\n",
       " 'v8663',\n",
       " 'yaasss',\n",
       " 'dv6403tx',\n",
       " 'bossbitches',\n",
       " '241q',\n",
       " 'rudimental',\n",
       " 'bored.yeap',\n",
       " 'lumias',\n",
       " 'e5410',\n",
       " 'legalalcoholic',\n",
       " 'naijaa',\n",
       " '0399',\n",
       " 'trystolookawaybutcant',\n",
       " 'currentlywatching',\n",
       " 'bbcdoctors',\n",
       " 'dvi-d-male',\n",
       " 'markteixeira',\n",
       " 'play.my',\n",
       " 'no-method',\n",
       " 'surmont',\n",
       " 'rejuven',\n",
       " 'andim',\n",
       " 'javoskin',\n",
       " 'mynextboyfriend',\n",
       " 'multi-compartment',\n",
       " 'imissmydishwasher',\n",
       " 'seered',\n",
       " 'parusa',\n",
       " 'aeden',\n",
       " '423ob',\n",
       " 'n0n',\n",
       " 'carson-dellosa',\n",
       " 'hajat',\n",
       " 'reumatologica',\n",
       " 'fmu',\n",
       " '803e',\n",
       " 'mega-city',\n",
       " 'naughtystudent',\n",
       " 'thingsthatmakeyougochale',\n",
       " 'bayweb',\n",
       " 'vv.aa',\n",
       " 'slashing',\n",
       " 'u86',\n",
       " \"k'nova\",\n",
       " 'awight',\n",
       " 'nycwantsdrakebell',\n",
       " 'l143',\n",
       " 'wetfeet',\n",
       " '016-1886',\n",
       " 'theprincipal',\n",
       " 'wdnamerica',\n",
       " 'anni',\n",
       " \"arissa's\",\n",
       " 'shand',\n",
       " 'rhx',\n",
       " 'unbar',\n",
       " 'm5052',\n",
       " 'kover',\n",
       " 'teammuldoon',\n",
       " 'birdos',\n",
       " 'bigtimee',\n",
       " '556uw',\n",
       " 'cd_78',\n",
       " 'elablues',\n",
       " 'mapapanood',\n",
       " 'heinlein',\n",
       " 'worming',\n",
       " 'gel-original',\n",
       " 'guan',\n",
       " ...]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_in_dict = list(set(unknown_lem)- set(in_dict))\n",
    "not_in_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordsegment import load, segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cd78']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment('cd_78')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-e2b421c94074>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msegments\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msegment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnot_in_dict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-99-e2b421c94074>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msegments\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msegment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnot_in_dict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36msegment\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msegment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;34m\"Return list of words that is the best segmenation of `text`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misegment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36misegment\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0moffset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m             \u001b[0mprefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mchunk_words\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(text, previous)\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprefix_score\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Avoid recursion limit issues by dividing text into chunks, segmenting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36mcandidates\u001b[1;34m()\u001b[0m\n\u001b[0;32m    125\u001b[0m                     \u001b[0mpair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                         \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m                     \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(text, previous)\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprefix_score\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Avoid recursion limit issues by dividing text into chunks, segmenting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36mcandidates\u001b[1;34m()\u001b[0m\n\u001b[0;32m    125\u001b[0m                     \u001b[0mpair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                         \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m                     \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(text, previous)\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprefix_score\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Avoid recursion limit issues by dividing text into chunks, segmenting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36mcandidates\u001b[1;34m()\u001b[0m\n\u001b[0;32m    125\u001b[0m                     \u001b[0mpair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                         \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m                     \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(text, previous)\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprefix_score\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Avoid recursion limit issues by dividing text into chunks, segmenting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36mcandidates\u001b[1;34m()\u001b[0m\n\u001b[0;32m    125\u001b[0m                     \u001b[0mpair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                         \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m                     \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(text, previous)\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprefix_score\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Avoid recursion limit issues by dividing text into chunks, segmenting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36mcandidates\u001b[1;34m()\u001b[0m\n\u001b[0;32m    125\u001b[0m                     \u001b[0mpair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                         \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m                     \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(text, previous)\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprefix_score\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Avoid recursion limit issues by dividing text into chunks, segmenting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36mcandidates\u001b[1;34m()\u001b[0m\n\u001b[0;32m    125\u001b[0m                     \u001b[0mpair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                         \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m                     \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(text, previous)\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprefix_score\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Avoid recursion limit issues by dividing text into chunks, segmenting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36mcandidates\u001b[1;34m()\u001b[0m\n\u001b[0;32m    125\u001b[0m                     \u001b[0mpair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                         \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m                     \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(text, previous)\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprefix_score\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Avoid recursion limit issues by dividing text into chunks, segmenting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36mcandidates\u001b[1;34m()\u001b[0m\n\u001b[0;32m    125\u001b[0m                     \u001b[0mpair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                         \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m                     \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(text, previous)\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprefix_score\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Avoid recursion limit issues by dividing text into chunks, segmenting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36mcandidates\u001b[1;34m()\u001b[0m\n\u001b[0;32m    125\u001b[0m                     \u001b[0mpair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                         \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m                     \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(text, previous)\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprefix_score\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[1;31m# Avoid recursion limit issues by dividing text into chunks, segmenting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36mcandidates\u001b[1;34m()\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[1;34m\"Generator of (score, words) pairs for all divisions of text.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                     \u001b[0mprefix_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m                     \u001b[0mpair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, word, previous)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;31m# Fall back to using the unigram probability.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\wordsegment\\__init__.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, word, previous)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[1;34m\"Score `word` in the context of `previous` word.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0munigrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munigrams\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "segments =[[w, segment(w)] for w in not_in_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
