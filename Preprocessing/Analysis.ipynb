{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import pickle\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "\ttknzr = TweetTokenizer()\n",
    "\treturn tknzr.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_csv_submission(ids, y_pred, name):\n",
    "    \"\"\"\n",
    "    Creates an output file in csv format for submission to kaggle\n",
    "    Arguments: ids (event ids associated with each prediction)\n",
    "               y_pred (predicted class labels)\n",
    "               name (string name of .csv output file to be created)\n",
    "    \"\"\"\n",
    "    idx = time.time()\n",
    "    name += str(idx) +'.csv'\n",
    "    with open(name, 'w') as csvfile:\n",
    "        fieldnames = ['Id', 'Prediction']\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "            writer.writerow({'Id':int(r1),'Prediction':int(r2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('dumped_files/corrected_datasets_pos_neg_test.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_dict = data = pickle.load(open('dumped_files/final_tokens_dictionary.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(604480, 387494)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_dict), len(set(final_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = list(set(data[0]))\n",
    "neg = list(set(data[1]))\n",
    "test = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tokens = []\n",
    "for tweet in pos:\n",
    "    pos_tokens.append([lemmatizer.lemmatize(w) for w in tokenize(tweet)])\n",
    "pos_counter = Counter([tk for tokens in pos_tokens for tk in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_tokens = []\n",
    "for tweet in neg:\n",
    "    neg_tokens.append([lemmatizer.lemmatize(w) for w in tokenize(tweet)])\n",
    "neg_counter = Counter([tk for tokens in neg_tokens for tk in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_most = pos_counter.most_common()\n",
    "neg_most = neg_counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_dict = {}\n",
    "for (w, f) in pos_most:\n",
    "    pos_dict[w] = f\n",
    "neg_dict = {}\n",
    "for (w, f) in neg_most:\n",
    "    neg_dict[w] = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = list(set(list(pos_dict) + list(neg_dict)))\n",
    "pos_frq = [pos_dict[w] if w in pos_dict else 0 for w in all_words]\n",
    "neg_frq = [neg_dict[w] if w in neg_dict else 0 for w in all_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = {'word' : all_words, 'pos':pos_frq, 'neg':neg_frq}\n",
    "df = pd.DataFrame(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['pos_ratio'] = df.apply(lambda row: round(100*row['pos']/(row['pos']+row['neg']),2), axis=1)\n",
    "df['neg_ratio'] = df.apply(lambda row: 100 - row['pos_ratio'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_ratio</th>\n",
       "      <th>neg_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rosamund</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>priscilla</th>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>40.82</td>\n",
       "      <td>59.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simoncelli</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50.00</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uproot</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>14.29</td>\n",
       "      <td>85.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parcel</th>\n",
       "      <td>48</td>\n",
       "      <td>53</td>\n",
       "      <td>52.48</td>\n",
       "      <td>47.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bucket</th>\n",
       "      <td>252</td>\n",
       "      <td>228</td>\n",
       "      <td>47.50</td>\n",
       "      <td>52.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muschamp</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expose</th>\n",
       "      <td>214</td>\n",
       "      <td>68</td>\n",
       "      <td>24.11</td>\n",
       "      <td>75.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonofabitch</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assemblage</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lamplight</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strove</th>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>73.33</td>\n",
       "      <td>26.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tacet</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>22.22</td>\n",
       "      <td>77.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earlimart</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tullahoma</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optronics</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rachmaninov</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expound</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.00</td>\n",
       "      <td>75.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweaktown</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abundantly</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>80.95</td>\n",
       "      <td>19.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             neg  pos  pos_ratio  neg_ratio\n",
       "word                                       \n",
       "rosamund       1    0       0.00     100.00\n",
       "priscilla     29   20      40.82      59.18\n",
       "simoncelli     1    1      50.00      50.00\n",
       "uproot         6    1      14.29      85.71\n",
       "parcel        48   53      52.48      47.52\n",
       "bucket       252  228      47.50      52.50\n",
       "muschamp       1    0       0.00     100.00\n",
       "expose       214   68      24.11      75.89\n",
       "sonofabitch    9    0       0.00     100.00\n",
       "assemblage     6    0       0.00     100.00\n",
       "lamplight      2    0       0.00     100.00\n",
       "strove         8   22      73.33      26.67\n",
       "tacet          7    2      22.22      77.78\n",
       "earlimart      1    0       0.00     100.00\n",
       "tullahoma      1    0       0.00     100.00\n",
       "optronics      1    0       0.00     100.00\n",
       "rachmaninov    2    0       0.00     100.00\n",
       "expound        3    1      25.00      75.00\n",
       "tweaktown      3    0       0.00     100.00\n",
       "abundantly     4   17      80.95      19.05"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.set_index('word')\n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['abs_diff'] = df.apply(lambda row: np.abs(row['pos_ratio']-row['neg_ratio']), axis=1)\n",
    "df['total'] = df.apply(lambda row: row['pos']+row['neg'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_ratio</th>\n",
       "      <th>neg_ratio</th>\n",
       "      <th>abs_diff</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>picture</th>\n",
       "      <td>6499</td>\n",
       "      <td>6498</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yeh</th>\n",
       "      <td>1550</td>\n",
       "      <td>1550</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headed</th>\n",
       "      <td>522</td>\n",
       "      <td>522</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1044.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dating</th>\n",
       "      <td>469</td>\n",
       "      <td>469</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>938.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loo</th>\n",
       "      <td>331</td>\n",
       "      <td>331</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>662.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qua</th>\n",
       "      <td>302</td>\n",
       "      <td>302</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leo</th>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>472.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thalia</th>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>darling</th>\n",
       "      <td>157</td>\n",
       "      <td>157</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>314.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kp</th>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setup</th>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bliss</th>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banana</th>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omer</th>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tassie</th>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>khan</th>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inform</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>munch</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whiskey</th>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sonya</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freshet</th>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>croatia</th>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stubborn</th>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slag</th>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toon</th>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muff</th>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statute</th>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepsis</th>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wank</th>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orzechowski</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gibber</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>typified</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interlocutory</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kulkarni</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotherhithe</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>achaian</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>centrifuged</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jagsfadkjdhfnh</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarksburg</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schizophr</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cipokpipigembungnya</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peewit</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuckahoe</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>komatik</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nitelife</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roguish</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naqoyqatsi</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snorkelers</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peluche</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actionaid</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnookin</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eulogize</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nontransparent</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stablemate</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rosamund</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muschamp</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earlimart</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tullahoma</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optronics</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51589 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      neg   pos  pos_ratio  neg_ratio  abs_diff    total\n",
       "word                                                                    \n",
       "picture              6499  6498       50.0       50.0       0.0  12997.0\n",
       "yeh                  1550  1550       50.0       50.0       0.0   3100.0\n",
       "headed                522   522       50.0       50.0       0.0   1044.0\n",
       "dating                469   469       50.0       50.0       0.0    938.0\n",
       "loo                   331   331       50.0       50.0       0.0    662.0\n",
       "qua                   302   302       50.0       50.0       0.0    604.0\n",
       "leo                   236   236       50.0       50.0       0.0    472.0\n",
       "thalia                187   187       50.0       50.0       0.0    374.0\n",
       "darling               157   157       50.0       50.0       0.0    314.0\n",
       "kp                    146   146       50.0       50.0       0.0    292.0\n",
       "setup                 129   129       50.0       50.0       0.0    258.0\n",
       "bliss                 126   126       50.0       50.0       0.0    252.0\n",
       "banana                119   119       50.0       50.0       0.0    238.0\n",
       "omer                  115   115       50.0       50.0       0.0    230.0\n",
       "tassie                107   107       50.0       50.0       0.0    214.0\n",
       "khan                  104   104       50.0       50.0       0.0    208.0\n",
       "inform                101   101       50.0       50.0       0.0    202.0\n",
       "munch                 100   100       50.0       50.0       0.0    200.0\n",
       "whiskey                99    99       50.0       50.0       0.0    198.0\n",
       "valid                  94    94       50.0       50.0       0.0    188.0\n",
       "sonya                  90    90       50.0       50.0       0.0    180.0\n",
       "freshet                88    88       50.0       50.0       0.0    176.0\n",
       "croatia                88    88       50.0       50.0       0.0    176.0\n",
       "stubborn               78    78       50.0       50.0       0.0    156.0\n",
       "slag                   76    76       50.0       50.0       0.0    152.0\n",
       "toon                   75    75       50.0       50.0       0.0    150.0\n",
       "muff                   75    75       50.0       50.0       0.0    150.0\n",
       "statute                70    70       50.0       50.0       0.0    140.0\n",
       "sepsis                 68    68       50.0       50.0       0.0    136.0\n",
       "wank                   62    62       50.0       50.0       0.0    124.0\n",
       "...                   ...   ...        ...        ...       ...      ...\n",
       "orzechowski             0     1      100.0        0.0     100.0      1.0\n",
       "gibber                  0     1      100.0        0.0     100.0      1.0\n",
       "typified                1     0        0.0      100.0     100.0      1.0\n",
       "interlocutory           1     0        0.0      100.0     100.0      1.0\n",
       "kulkarni                0     1      100.0        0.0     100.0      1.0\n",
       "rotherhithe             1     0        0.0      100.0     100.0      1.0\n",
       "achaian                 1     0        0.0      100.0     100.0      1.0\n",
       "centrifuged             1     0        0.0      100.0     100.0      1.0\n",
       "jagsfadkjdhfnh          1     0        0.0      100.0     100.0      1.0\n",
       "clarksburg              0     1      100.0        0.0     100.0      1.0\n",
       "schizophr               1     0        0.0      100.0     100.0      1.0\n",
       "cipokpipigembungnya     0     1      100.0        0.0     100.0      1.0\n",
       "peewit                  1     0        0.0      100.0     100.0      1.0\n",
       "tuckahoe                1     0        0.0      100.0     100.0      1.0\n",
       "komatik                 0     1      100.0        0.0     100.0      1.0\n",
       "nitelife                1     0        0.0      100.0     100.0      1.0\n",
       "roguish                 1     0        0.0      100.0     100.0      1.0\n",
       "naqoyqatsi              1     0        0.0      100.0     100.0      1.0\n",
       "snorkelers              1     0        0.0      100.0     100.0      1.0\n",
       "peluche                 0     1      100.0        0.0     100.0      1.0\n",
       "actionaid               1     0        0.0      100.0     100.0      1.0\n",
       "mnookin                 1     0        0.0      100.0     100.0      1.0\n",
       "eulogize                1     0        0.0      100.0     100.0      1.0\n",
       "nontransparent          1     0        0.0      100.0     100.0      1.0\n",
       "stablemate              1     0        0.0      100.0     100.0      1.0\n",
       "rosamund                1     0        0.0      100.0     100.0      1.0\n",
       "muschamp                1     0        0.0      100.0     100.0      1.0\n",
       "earlimart               1     0        0.0      100.0     100.0      1.0\n",
       "tullahoma               1     0        0.0      100.0     100.0      1.0\n",
       "optronics               1     0        0.0      100.0     100.0      1.0\n",
       "\n",
       "[51589 rows x 6 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['abs_diff', 'total'], ascending=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = [line.rstrip('\\n').lower() for line in open('data/stopwords.txt')] + ['user', 'url', 'rt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['word_'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_df = df.loc[df.apply(lambda row: row['word_'] in stop_words, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_ratio</th>\n",
       "      <th>neg_ratio</th>\n",
       "      <th>abs_diff</th>\n",
       "      <th>total</th>\n",
       "      <th>word_</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>what</th>\n",
       "      <td>114135</td>\n",
       "      <td>114025</td>\n",
       "      <td>49.98</td>\n",
       "      <td>50.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>228160.0</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>after</th>\n",
       "      <td>10126</td>\n",
       "      <td>10043</td>\n",
       "      <td>49.79</td>\n",
       "      <td>50.21</td>\n",
       "      <td>0.42</td>\n",
       "      <td>20169.0</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td>6806</td>\n",
       "      <td>6880</td>\n",
       "      <td>50.27</td>\n",
       "      <td>49.73</td>\n",
       "      <td>0.54</td>\n",
       "      <td>13686.0</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>255742</td>\n",
       "      <td>252745</td>\n",
       "      <td>49.71</td>\n",
       "      <td>50.29</td>\n",
       "      <td>0.58</td>\n",
       "      <td>508487.0</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>themselves</th>\n",
       "      <td>294</td>\n",
       "      <td>290</td>\n",
       "      <td>49.66</td>\n",
       "      <td>50.34</td>\n",
       "      <td>0.68</td>\n",
       "      <td>584.0</td>\n",
       "      <td>themselves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>they</th>\n",
       "      <td>28936</td>\n",
       "      <td>28471</td>\n",
       "      <td>49.59</td>\n",
       "      <td>50.41</td>\n",
       "      <td>0.82</td>\n",
       "      <td>57407.0</td>\n",
       "      <td>they</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am</th>\n",
       "      <td>104757</td>\n",
       "      <td>102878</td>\n",
       "      <td>49.55</td>\n",
       "      <td>50.45</td>\n",
       "      <td>0.90</td>\n",
       "      <td>207635.0</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>being</th>\n",
       "      <td>23359</td>\n",
       "      <td>22881</td>\n",
       "      <td>49.48</td>\n",
       "      <td>50.52</td>\n",
       "      <td>1.04</td>\n",
       "      <td>46240.0</td>\n",
       "      <td>being</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do</th>\n",
       "      <td>93985</td>\n",
       "      <td>90265</td>\n",
       "      <td>48.99</td>\n",
       "      <td>51.01</td>\n",
       "      <td>2.02</td>\n",
       "      <td>184250.0</td>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>341120</td>\n",
       "      <td>326481</td>\n",
       "      <td>48.90</td>\n",
       "      <td>51.10</td>\n",
       "      <td>2.20</td>\n",
       "      <td>667601.0</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>him</th>\n",
       "      <td>16987</td>\n",
       "      <td>17767</td>\n",
       "      <td>51.12</td>\n",
       "      <td>48.88</td>\n",
       "      <td>2.24</td>\n",
       "      <td>34754.0</td>\n",
       "      <td>him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>which</th>\n",
       "      <td>3734</td>\n",
       "      <td>3564</td>\n",
       "      <td>48.84</td>\n",
       "      <td>51.16</td>\n",
       "      <td>2.32</td>\n",
       "      <td>7298.0</td>\n",
       "      <td>which</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at</th>\n",
       "      <td>60308</td>\n",
       "      <td>57411</td>\n",
       "      <td>48.77</td>\n",
       "      <td>51.23</td>\n",
       "      <td>2.46</td>\n",
       "      <td>117719.0</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>have</th>\n",
       "      <td>110465</td>\n",
       "      <td>104187</td>\n",
       "      <td>48.54</td>\n",
       "      <td>51.46</td>\n",
       "      <td>2.92</td>\n",
       "      <td>214652.0</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>such</th>\n",
       "      <td>5467</td>\n",
       "      <td>5843</td>\n",
       "      <td>51.66</td>\n",
       "      <td>48.34</td>\n",
       "      <td>3.32</td>\n",
       "      <td>11310.0</td>\n",
       "      <td>such</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>their</th>\n",
       "      <td>6982</td>\n",
       "      <td>6527</td>\n",
       "      <td>48.32</td>\n",
       "      <td>51.68</td>\n",
       "      <td>3.36</td>\n",
       "      <td>13509.0</td>\n",
       "      <td>their</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>before</th>\n",
       "      <td>7379</td>\n",
       "      <td>7918</td>\n",
       "      <td>51.76</td>\n",
       "      <td>48.24</td>\n",
       "      <td>3.52</td>\n",
       "      <td>15297.0</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>up</th>\n",
       "      <td>57762</td>\n",
       "      <td>61995</td>\n",
       "      <td>51.77</td>\n",
       "      <td>48.23</td>\n",
       "      <td>3.54</td>\n",
       "      <td>119757.0</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>135543</td>\n",
       "      <td>145487</td>\n",
       "      <td>51.77</td>\n",
       "      <td>48.23</td>\n",
       "      <td>3.54</td>\n",
       "      <td>281030.0</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>or</th>\n",
       "      <td>26332</td>\n",
       "      <td>24509</td>\n",
       "      <td>48.21</td>\n",
       "      <td>51.79</td>\n",
       "      <td>3.58</td>\n",
       "      <td>50841.0</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>having</th>\n",
       "      <td>7507</td>\n",
       "      <td>6988</td>\n",
       "      <td>48.21</td>\n",
       "      <td>51.79</td>\n",
       "      <td>3.58</td>\n",
       "      <td>14495.0</td>\n",
       "      <td>having</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>109010</td>\n",
       "      <td>101283</td>\n",
       "      <td>48.16</td>\n",
       "      <td>51.84</td>\n",
       "      <td>3.68</td>\n",
       "      <td>210293.0</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>were</th>\n",
       "      <td>12766</td>\n",
       "      <td>11800</td>\n",
       "      <td>48.03</td>\n",
       "      <td>51.97</td>\n",
       "      <td>3.94</td>\n",
       "      <td>24566.0</td>\n",
       "      <td>were</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>105953</td>\n",
       "      <td>114689</td>\n",
       "      <td>51.98</td>\n",
       "      <td>48.02</td>\n",
       "      <td>3.96</td>\n",
       "      <td>220642.0</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>224068</td>\n",
       "      <td>206003</td>\n",
       "      <td>47.90</td>\n",
       "      <td>52.10</td>\n",
       "      <td>4.20</td>\n",
       "      <td>430071.0</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>37404</td>\n",
       "      <td>40707</td>\n",
       "      <td>52.11</td>\n",
       "      <td>47.89</td>\n",
       "      <td>4.22</td>\n",
       "      <td>78111.0</td>\n",
       "      <td>too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>231631</td>\n",
       "      <td>253407</td>\n",
       "      <td>52.24</td>\n",
       "      <td>47.76</td>\n",
       "      <td>4.48</td>\n",
       "      <td>485038.0</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me</th>\n",
       "      <td>157273</td>\n",
       "      <td>172369</td>\n",
       "      <td>52.29</td>\n",
       "      <td>47.71</td>\n",
       "      <td>4.58</td>\n",
       "      <td>329642.0</td>\n",
       "      <td>me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>1262</td>\n",
       "      <td>1151</td>\n",
       "      <td>47.70</td>\n",
       "      <td>52.30</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3744</td>\n",
       "      <td>3404</td>\n",
       "      <td>47.62</td>\n",
       "      <td>52.38</td>\n",
       "      <td>4.76</td>\n",
       "      <td>7148.0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>18376</td>\n",
       "      <td>26688</td>\n",
       "      <td>59.22</td>\n",
       "      <td>40.78</td>\n",
       "      <td>18.44</td>\n",
       "      <td>45064.0</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>73282</td>\n",
       "      <td>106760</td>\n",
       "      <td>59.30</td>\n",
       "      <td>40.70</td>\n",
       "      <td>18.60</td>\n",
       "      <td>180042.0</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>both</th>\n",
       "      <td>3312</td>\n",
       "      <td>4832</td>\n",
       "      <td>59.33</td>\n",
       "      <td>40.67</td>\n",
       "      <td>18.66</td>\n",
       "      <td>8144.0</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>through</th>\n",
       "      <td>5462</td>\n",
       "      <td>3703</td>\n",
       "      <td>40.40</td>\n",
       "      <td>59.60</td>\n",
       "      <td>19.20</td>\n",
       "      <td>9165.0</td>\n",
       "      <td>through</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who</th>\n",
       "      <td>17303</td>\n",
       "      <td>25853</td>\n",
       "      <td>59.91</td>\n",
       "      <td>40.09</td>\n",
       "      <td>19.82</td>\n",
       "      <td>43156.0</td>\n",
       "      <td>who</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>these</th>\n",
       "      <td>9358</td>\n",
       "      <td>6216</td>\n",
       "      <td>39.91</td>\n",
       "      <td>60.09</td>\n",
       "      <td>20.18</td>\n",
       "      <td>15574.0</td>\n",
       "      <td>these</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>under</th>\n",
       "      <td>2247</td>\n",
       "      <td>1454</td>\n",
       "      <td>39.29</td>\n",
       "      <td>60.71</td>\n",
       "      <td>21.42</td>\n",
       "      <td>3701.0</td>\n",
       "      <td>under</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>then</th>\n",
       "      <td>16171</td>\n",
       "      <td>25213</td>\n",
       "      <td>60.92</td>\n",
       "      <td>39.08</td>\n",
       "      <td>21.84</td>\n",
       "      <td>41384.0</td>\n",
       "      <td>then</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>789</td>\n",
       "      <td>503</td>\n",
       "      <td>38.93</td>\n",
       "      <td>61.07</td>\n",
       "      <td>22.14</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>each</th>\n",
       "      <td>4613</td>\n",
       "      <td>2931</td>\n",
       "      <td>38.85</td>\n",
       "      <td>61.15</td>\n",
       "      <td>22.30</td>\n",
       "      <td>7544.0</td>\n",
       "      <td>each</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>will</th>\n",
       "      <td>56565</td>\n",
       "      <td>90996</td>\n",
       "      <td>61.67</td>\n",
       "      <td>38.33</td>\n",
       "      <td>23.34</td>\n",
       "      <td>147561.0</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doing</th>\n",
       "      <td>6926</td>\n",
       "      <td>11200</td>\n",
       "      <td>61.79</td>\n",
       "      <td>38.21</td>\n",
       "      <td>23.58</td>\n",
       "      <td>18126.0</td>\n",
       "      <td>doing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ours</th>\n",
       "      <td>438</td>\n",
       "      <td>713</td>\n",
       "      <td>61.95</td>\n",
       "      <td>38.05</td>\n",
       "      <td>23.90</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>ours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>below</th>\n",
       "      <td>222</td>\n",
       "      <td>136</td>\n",
       "      <td>37.99</td>\n",
       "      <td>62.01</td>\n",
       "      <td>24.02</td>\n",
       "      <td>358.0</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter</th>\n",
       "      <td>9167</td>\n",
       "      <td>15171</td>\n",
       "      <td>62.33</td>\n",
       "      <td>37.67</td>\n",
       "      <td>24.66</td>\n",
       "      <td>24338.0</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ourselves</th>\n",
       "      <td>122</td>\n",
       "      <td>202</td>\n",
       "      <td>62.35</td>\n",
       "      <td>37.65</td>\n",
       "      <td>24.70</td>\n",
       "      <td>324.0</td>\n",
       "      <td>ourselves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>some</th>\n",
       "      <td>15828</td>\n",
       "      <td>26246</td>\n",
       "      <td>62.38</td>\n",
       "      <td>37.62</td>\n",
       "      <td>24.76</td>\n",
       "      <td>42074.0</td>\n",
       "      <td>some</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <td>552830</td>\n",
       "      <td>941130</td>\n",
       "      <td>63.00</td>\n",
       "      <td>37.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>1493960.0</td>\n",
       "      <td>user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itself</th>\n",
       "      <td>332</td>\n",
       "      <td>188</td>\n",
       "      <td>36.15</td>\n",
       "      <td>63.85</td>\n",
       "      <td>27.70</td>\n",
       "      <td>520.0</td>\n",
       "      <td>itself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your</th>\n",
       "      <td>53067</td>\n",
       "      <td>94672</td>\n",
       "      <td>64.08</td>\n",
       "      <td>35.92</td>\n",
       "      <td>28.16</td>\n",
       "      <td>147739.0</td>\n",
       "      <td>your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>if</th>\n",
       "      <td>28888</td>\n",
       "      <td>53354</td>\n",
       "      <td>64.87</td>\n",
       "      <td>35.13</td>\n",
       "      <td>29.74</td>\n",
       "      <td>82242.0</td>\n",
       "      <td>if</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>238349</td>\n",
       "      <td>449163</td>\n",
       "      <td>65.33</td>\n",
       "      <td>34.67</td>\n",
       "      <td>30.66</td>\n",
       "      <td>687512.0</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>78999</td>\n",
       "      <td>163949</td>\n",
       "      <td>67.48</td>\n",
       "      <td>32.52</td>\n",
       "      <td>34.96</td>\n",
       "      <td>242948.0</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>4886</td>\n",
       "      <td>10657</td>\n",
       "      <td>68.56</td>\n",
       "      <td>31.44</td>\n",
       "      <td>37.12</td>\n",
       "      <td>15543.0</td>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>664</td>\n",
       "      <td>281</td>\n",
       "      <td>29.74</td>\n",
       "      <td>70.26</td>\n",
       "      <td>40.52</td>\n",
       "      <td>945.0</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yours</th>\n",
       "      <td>1528</td>\n",
       "      <td>3617</td>\n",
       "      <td>70.30</td>\n",
       "      <td>29.70</td>\n",
       "      <td>40.60</td>\n",
       "      <td>5145.0</td>\n",
       "      <td>yours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>why</th>\n",
       "      <td>36532</td>\n",
       "      <td>14640</td>\n",
       "      <td>28.61</td>\n",
       "      <td>71.39</td>\n",
       "      <td>42.78</td>\n",
       "      <td>51172.0</td>\n",
       "      <td>why</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ll</th>\n",
       "      <td>355</td>\n",
       "      <td>1074</td>\n",
       "      <td>75.16</td>\n",
       "      <td>24.84</td>\n",
       "      <td>50.32</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yourselves</th>\n",
       "      <td>23</td>\n",
       "      <td>70</td>\n",
       "      <td>75.27</td>\n",
       "      <td>24.73</td>\n",
       "      <td>50.54</td>\n",
       "      <td>93.0</td>\n",
       "      <td>yourselves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url</th>\n",
       "      <td>324077</td>\n",
       "      <td>83817</td>\n",
       "      <td>20.55</td>\n",
       "      <td>79.45</td>\n",
       "      <td>58.90</td>\n",
       "      <td>407894.0</td>\n",
       "      <td>url</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               neg     pos  pos_ratio  neg_ratio  abs_diff      total  \\\n",
       "word                                                                    \n",
       "what        114135  114025      49.98      50.02      0.04   228160.0   \n",
       "after        10126   10043      49.79      50.21      0.42    20169.0   \n",
       "be            6806    6880      50.27      49.73      0.54    13686.0   \n",
       "my          255742  252745      49.71      50.29      0.58   508487.0   \n",
       "themselves     294     290      49.66      50.34      0.68      584.0   \n",
       "they         28936   28471      49.59      50.41      0.82    57407.0   \n",
       "am          104757  102878      49.55      50.45      0.90   207635.0   \n",
       "being        23359   22881      49.48      50.52      1.04    46240.0   \n",
       "do           93985   90265      48.99      51.01      2.02   184250.0   \n",
       "to          341120  326481      48.90      51.10      2.20   667601.0   \n",
       "him          16987   17767      51.12      48.88      2.24    34754.0   \n",
       "which         3734    3564      48.84      51.16      2.32     7298.0   \n",
       "at           60308   57411      48.77      51.23      2.46   117719.0   \n",
       "have        110465  104187      48.54      51.46      2.92   214652.0   \n",
       "such          5467    5843      51.66      48.34      3.32    11310.0   \n",
       "their         6982    6527      48.32      51.68      3.36    13509.0   \n",
       "before        7379    7918      51.76      48.24      3.52    15297.0   \n",
       "up           57762   61995      51.77      48.23      3.54   119757.0   \n",
       "for         135543  145487      51.77      48.23      3.54   281030.0   \n",
       "or           26332   24509      48.21      51.79      3.58    50841.0   \n",
       "having        7507    6988      48.21      51.79      3.58    14495.0   \n",
       "other       109010  101283      48.16      51.84      3.68   210293.0   \n",
       "were         12766   11800      48.03      51.97      3.94    24566.0   \n",
       "with        105953  114689      51.98      48.02      3.96   220642.0   \n",
       "in          224068  206003      47.90      52.10      4.20   430071.0   \n",
       "too          37404   40707      52.11      47.89      4.22    78111.0   \n",
       "is          231631  253407      52.24      47.76      4.48   485038.0   \n",
       "me          157273  172369      52.29      47.71      4.58   329642.0   \n",
       "m             1262    1151      47.70      52.30      4.60     2413.0   \n",
       "a             3744    3404      47.62      52.38      4.76     7148.0   \n",
       "...            ...     ...        ...        ...       ...        ...   \n",
       "as           18376   26688      59.22      40.78     18.44    45064.0   \n",
       "are          73282  106760      59.30      40.70     18.60   180042.0   \n",
       "both          3312    4832      59.33      40.67     18.66     8144.0   \n",
       "through       5462    3703      40.40      59.60     19.20     9165.0   \n",
       "who          17303   25853      59.91      40.09     19.82    43156.0   \n",
       "these         9358    6216      39.91      60.09     20.18    15574.0   \n",
       "under         2247    1454      39.29      60.71     21.42     3701.0   \n",
       "then         16171   25213      60.92      39.08     21.84    41384.0   \n",
       "o              789     503      38.93      61.07     22.14     1292.0   \n",
       "each          4613    2931      38.85      61.15     22.30     7544.0   \n",
       "will         56565   90996      61.67      38.33     23.34   147561.0   \n",
       "doing         6926   11200      61.79      38.21     23.58    18126.0   \n",
       "ours           438     713      61.95      38.05     23.90     1151.0   \n",
       "below          222     136      37.99      62.01     24.02      358.0   \n",
       "twitter       9167   15171      62.33      37.67     24.66    24338.0   \n",
       "ourselves      122     202      62.35      37.65     24.70      324.0   \n",
       "some         15828   26246      62.38      37.62     24.76    42074.0   \n",
       "user        552830  941130      63.00      37.00     26.00  1493960.0   \n",
       "itself         332     188      36.15      63.85     27.70      520.0   \n",
       "your         53067   94672      64.08      35.92     28.16   147739.0   \n",
       "if           28888   53354      64.87      35.13     29.74    82242.0   \n",
       "you         238349  449163      65.33      34.67     30.66   687512.0   \n",
       "of           78999  163949      67.48      32.52     34.96   242948.0   \n",
       "we            4886   10657      68.56      31.44     37.12    15543.0   \n",
       "d              664     281      29.74      70.26     40.52      945.0   \n",
       "yours         1528    3617      70.30      29.70     40.60     5145.0   \n",
       "why          36532   14640      28.61      71.39     42.78    51172.0   \n",
       "ll             355    1074      75.16      24.84     50.32     1429.0   \n",
       "yourselves      23      70      75.27      24.73     50.54       93.0   \n",
       "url         324077   83817      20.55      79.45     58.90   407894.0   \n",
       "\n",
       "                 word_  \n",
       "word                    \n",
       "what              what  \n",
       "after            after  \n",
       "be                  be  \n",
       "my                  my  \n",
       "themselves  themselves  \n",
       "they              they  \n",
       "am                  am  \n",
       "being            being  \n",
       "do                  do  \n",
       "to                  to  \n",
       "him                him  \n",
       "which            which  \n",
       "at                  at  \n",
       "have              have  \n",
       "such              such  \n",
       "their            their  \n",
       "before          before  \n",
       "up                  up  \n",
       "for                for  \n",
       "or                  or  \n",
       "having          having  \n",
       "other            other  \n",
       "were              were  \n",
       "with              with  \n",
       "in                  in  \n",
       "too                too  \n",
       "is                  is  \n",
       "me                  me  \n",
       "m                    m  \n",
       "a                    a  \n",
       "...                ...  \n",
       "as                  as  \n",
       "are                are  \n",
       "both              both  \n",
       "through        through  \n",
       "who                who  \n",
       "these            these  \n",
       "under            under  \n",
       "then              then  \n",
       "o                    o  \n",
       "each              each  \n",
       "will              will  \n",
       "doing            doing  \n",
       "ours              ours  \n",
       "below            below  \n",
       "twitter        twitter  \n",
       "ourselves    ourselves  \n",
       "some              some  \n",
       "user              user  \n",
       "itself          itself  \n",
       "your              your  \n",
       "if                  if  \n",
       "you                you  \n",
       "of                  of  \n",
       "we                  we  \n",
       "d                    d  \n",
       "yours            yours  \n",
       "why                why  \n",
       "ll                  ll  \n",
       "yourselves  yourselves  \n",
       "url                url  \n",
       "\n",
       "[123 rows x 7 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_df.sort_values(['abs_diff'], ascending=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_ratio</th>\n",
       "      <th>neg_ratio</th>\n",
       "      <th>abs_diff</th>\n",
       "      <th>total</th>\n",
       "      <th>word_</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>have</th>\n",
       "      <td>110465</td>\n",
       "      <td>104187</td>\n",
       "      <td>48.54</td>\n",
       "      <td>51.46</td>\n",
       "      <td>2.92</td>\n",
       "      <td>214652.0</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>1262</td>\n",
       "      <td>1151</td>\n",
       "      <td>47.70</td>\n",
       "      <td>52.30</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>42010</td>\n",
       "      <td>35427</td>\n",
       "      <td>45.75</td>\n",
       "      <td>54.25</td>\n",
       "      <td>8.50</td>\n",
       "      <td>77437.0</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at</th>\n",
       "      <td>60308</td>\n",
       "      <td>57411</td>\n",
       "      <td>48.77</td>\n",
       "      <td>51.23</td>\n",
       "      <td>2.46</td>\n",
       "      <td>117719.0</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>she</th>\n",
       "      <td>25201</td>\n",
       "      <td>32088</td>\n",
       "      <td>56.01</td>\n",
       "      <td>43.99</td>\n",
       "      <td>12.02</td>\n",
       "      <td>57289.0</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do</th>\n",
       "      <td>93985</td>\n",
       "      <td>90265</td>\n",
       "      <td>48.99</td>\n",
       "      <td>51.01</td>\n",
       "      <td>2.02</td>\n",
       "      <td>184250.0</td>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>our</th>\n",
       "      <td>11178</td>\n",
       "      <td>14147</td>\n",
       "      <td>55.86</td>\n",
       "      <td>44.14</td>\n",
       "      <td>11.72</td>\n",
       "      <td>25325.0</td>\n",
       "      <td>our</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>before</th>\n",
       "      <td>7379</td>\n",
       "      <td>7918</td>\n",
       "      <td>51.76</td>\n",
       "      <td>48.24</td>\n",
       "      <td>3.52</td>\n",
       "      <td>15297.0</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>herself</th>\n",
       "      <td>318</td>\n",
       "      <td>234</td>\n",
       "      <td>42.39</td>\n",
       "      <td>57.61</td>\n",
       "      <td>15.22</td>\n",
       "      <td>552.0</td>\n",
       "      <td>herself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>into</th>\n",
       "      <td>6887</td>\n",
       "      <td>5165</td>\n",
       "      <td>42.86</td>\n",
       "      <td>57.14</td>\n",
       "      <td>14.28</td>\n",
       "      <td>12052.0</td>\n",
       "      <td>into</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am</th>\n",
       "      <td>104757</td>\n",
       "      <td>102878</td>\n",
       "      <td>49.55</td>\n",
       "      <td>50.45</td>\n",
       "      <td>0.90</td>\n",
       "      <td>207635.0</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>than</th>\n",
       "      <td>9042</td>\n",
       "      <td>11936</td>\n",
       "      <td>56.90</td>\n",
       "      <td>43.10</td>\n",
       "      <td>13.80</td>\n",
       "      <td>20978.0</td>\n",
       "      <td>than</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>being</th>\n",
       "      <td>23359</td>\n",
       "      <td>22881</td>\n",
       "      <td>49.48</td>\n",
       "      <td>50.52</td>\n",
       "      <td>1.04</td>\n",
       "      <td>46240.0</td>\n",
       "      <td>being</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt</th>\n",
       "      <td>286</td>\n",
       "      <td>319</td>\n",
       "      <td>52.73</td>\n",
       "      <td>47.27</td>\n",
       "      <td>5.46</td>\n",
       "      <td>605.0</td>\n",
       "      <td>rt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yourself</th>\n",
       "      <td>3622</td>\n",
       "      <td>4226</td>\n",
       "      <td>53.85</td>\n",
       "      <td>46.15</td>\n",
       "      <td>7.70</td>\n",
       "      <td>7848.0</td>\n",
       "      <td>yourself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>73282</td>\n",
       "      <td>106760</td>\n",
       "      <td>59.30</td>\n",
       "      <td>40.70</td>\n",
       "      <td>18.60</td>\n",
       "      <td>180042.0</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>224068</td>\n",
       "      <td>206003</td>\n",
       "      <td>47.90</td>\n",
       "      <td>52.10</td>\n",
       "      <td>4.20</td>\n",
       "      <td>430071.0</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <td>37442</td>\n",
       "      <td>31001</td>\n",
       "      <td>45.29</td>\n",
       "      <td>54.71</td>\n",
       "      <td>9.42</td>\n",
       "      <td>68443.0</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>about</th>\n",
       "      <td>27967</td>\n",
       "      <td>34287</td>\n",
       "      <td>55.08</td>\n",
       "      <td>44.92</td>\n",
       "      <td>10.16</td>\n",
       "      <td>62254.0</td>\n",
       "      <td>about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>which</th>\n",
       "      <td>3734</td>\n",
       "      <td>3564</td>\n",
       "      <td>48.84</td>\n",
       "      <td>51.16</td>\n",
       "      <td>2.32</td>\n",
       "      <td>7298.0</td>\n",
       "      <td>which</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who</th>\n",
       "      <td>17303</td>\n",
       "      <td>25853</td>\n",
       "      <td>59.91</td>\n",
       "      <td>40.09</td>\n",
       "      <td>19.82</td>\n",
       "      <td>43156.0</td>\n",
       "      <td>who</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>17262</td>\n",
       "      <td>23573</td>\n",
       "      <td>57.73</td>\n",
       "      <td>42.27</td>\n",
       "      <td>15.46</td>\n",
       "      <td>40835.0</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>231631</td>\n",
       "      <td>253407</td>\n",
       "      <td>52.24</td>\n",
       "      <td>47.76</td>\n",
       "      <td>4.48</td>\n",
       "      <td>485038.0</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>where</th>\n",
       "      <td>13330</td>\n",
       "      <td>10537</td>\n",
       "      <td>44.15</td>\n",
       "      <td>55.85</td>\n",
       "      <td>11.70</td>\n",
       "      <td>23867.0</td>\n",
       "      <td>where</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3744</td>\n",
       "      <td>3404</td>\n",
       "      <td>47.62</td>\n",
       "      <td>52.38</td>\n",
       "      <td>4.76</td>\n",
       "      <td>7148.0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>same</th>\n",
       "      <td>10951</td>\n",
       "      <td>8896</td>\n",
       "      <td>44.82</td>\n",
       "      <td>55.18</td>\n",
       "      <td>10.36</td>\n",
       "      <td>19847.0</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>those</th>\n",
       "      <td>5397</td>\n",
       "      <td>6602</td>\n",
       "      <td>55.02</td>\n",
       "      <td>44.98</td>\n",
       "      <td>10.04</td>\n",
       "      <td>11999.0</td>\n",
       "      <td>those</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>18376</td>\n",
       "      <td>26688</td>\n",
       "      <td>59.22</td>\n",
       "      <td>40.78</td>\n",
       "      <td>18.44</td>\n",
       "      <td>45064.0</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>37404</td>\n",
       "      <td>40707</td>\n",
       "      <td>52.11</td>\n",
       "      <td>47.89</td>\n",
       "      <td>4.22</td>\n",
       "      <td>78111.0</td>\n",
       "      <td>too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>255742</td>\n",
       "      <td>252745</td>\n",
       "      <td>49.71</td>\n",
       "      <td>50.29</td>\n",
       "      <td>0.58</td>\n",
       "      <td>508487.0</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>104636</td>\n",
       "      <td>140233</td>\n",
       "      <td>57.27</td>\n",
       "      <td>42.73</td>\n",
       "      <td>14.54</td>\n",
       "      <td>244869.0</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>they</th>\n",
       "      <td>28936</td>\n",
       "      <td>28471</td>\n",
       "      <td>49.59</td>\n",
       "      <td>50.41</td>\n",
       "      <td>0.82</td>\n",
       "      <td>57407.0</td>\n",
       "      <td>they</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>1254</td>\n",
       "      <td>1044</td>\n",
       "      <td>45.43</td>\n",
       "      <td>54.57</td>\n",
       "      <td>9.14</td>\n",
       "      <td>2298.0</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>while</th>\n",
       "      <td>5449</td>\n",
       "      <td>6031</td>\n",
       "      <td>52.53</td>\n",
       "      <td>47.47</td>\n",
       "      <td>5.06</td>\n",
       "      <td>11480.0</td>\n",
       "      <td>while</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can</th>\n",
       "      <td>65690</td>\n",
       "      <td>72478</td>\n",
       "      <td>52.46</td>\n",
       "      <td>47.54</td>\n",
       "      <td>4.92</td>\n",
       "      <td>138168.0</td>\n",
       "      <td>can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>or</th>\n",
       "      <td>26332</td>\n",
       "      <td>24509</td>\n",
       "      <td>48.21</td>\n",
       "      <td>51.79</td>\n",
       "      <td>3.58</td>\n",
       "      <td>50841.0</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>any</th>\n",
       "      <td>11209</td>\n",
       "      <td>9257</td>\n",
       "      <td>45.23</td>\n",
       "      <td>54.77</td>\n",
       "      <td>9.54</td>\n",
       "      <td>20466.0</td>\n",
       "      <td>any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>108975</td>\n",
       "      <td>121298</td>\n",
       "      <td>52.68</td>\n",
       "      <td>47.32</td>\n",
       "      <td>5.36</td>\n",
       "      <td>230273.0</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>135543</td>\n",
       "      <td>145487</td>\n",
       "      <td>51.77</td>\n",
       "      <td>48.23</td>\n",
       "      <td>3.54</td>\n",
       "      <td>281030.0</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td>6806</td>\n",
       "      <td>6880</td>\n",
       "      <td>50.27</td>\n",
       "      <td>49.73</td>\n",
       "      <td>0.54</td>\n",
       "      <td>13686.0</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>228597</td>\n",
       "      <td>206122</td>\n",
       "      <td>47.41</td>\n",
       "      <td>52.59</td>\n",
       "      <td>5.18</td>\n",
       "      <td>434719.0</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>what</th>\n",
       "      <td>114135</td>\n",
       "      <td>114025</td>\n",
       "      <td>49.98</td>\n",
       "      <td>50.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>228160.0</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>during</th>\n",
       "      <td>2417</td>\n",
       "      <td>3054</td>\n",
       "      <td>55.82</td>\n",
       "      <td>44.18</td>\n",
       "      <td>11.64</td>\n",
       "      <td>5471.0</td>\n",
       "      <td>during</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>126</td>\n",
       "      <td>93</td>\n",
       "      <td>42.47</td>\n",
       "      <td>57.53</td>\n",
       "      <td>15.06</td>\n",
       "      <td>219.0</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>13752</td>\n",
       "      <td>12444</td>\n",
       "      <td>47.50</td>\n",
       "      <td>52.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>26196.0</td>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over</th>\n",
       "      <td>21835</td>\n",
       "      <td>18587</td>\n",
       "      <td>45.98</td>\n",
       "      <td>54.02</td>\n",
       "      <td>8.04</td>\n",
       "      <td>40422.0</td>\n",
       "      <td>over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>most</th>\n",
       "      <td>8358</td>\n",
       "      <td>5963</td>\n",
       "      <td>41.64</td>\n",
       "      <td>58.36</td>\n",
       "      <td>16.72</td>\n",
       "      <td>14321.0</td>\n",
       "      <td>most</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>own</th>\n",
       "      <td>4281</td>\n",
       "      <td>4910</td>\n",
       "      <td>53.42</td>\n",
       "      <td>46.58</td>\n",
       "      <td>6.84</td>\n",
       "      <td>9191.0</td>\n",
       "      <td>own</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>after</th>\n",
       "      <td>10126</td>\n",
       "      <td>10043</td>\n",
       "      <td>49.79</td>\n",
       "      <td>50.21</td>\n",
       "      <td>0.42</td>\n",
       "      <td>20169.0</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>when</th>\n",
       "      <td>46071</td>\n",
       "      <td>41480</td>\n",
       "      <td>47.38</td>\n",
       "      <td>52.62</td>\n",
       "      <td>5.24</td>\n",
       "      <td>87551.0</td>\n",
       "      <td>when</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>341120</td>\n",
       "      <td>326481</td>\n",
       "      <td>48.90</td>\n",
       "      <td>51.10</td>\n",
       "      <td>2.20</td>\n",
       "      <td>667601.0</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>once</th>\n",
       "      <td>3696</td>\n",
       "      <td>4747</td>\n",
       "      <td>56.22</td>\n",
       "      <td>43.78</td>\n",
       "      <td>12.44</td>\n",
       "      <td>8443.0</td>\n",
       "      <td>once</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whom</th>\n",
       "      <td>279</td>\n",
       "      <td>194</td>\n",
       "      <td>41.01</td>\n",
       "      <td>58.99</td>\n",
       "      <td>17.98</td>\n",
       "      <td>473.0</td>\n",
       "      <td>whom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>66559</td>\n",
       "      <td>83395</td>\n",
       "      <td>55.61</td>\n",
       "      <td>44.39</td>\n",
       "      <td>11.22</td>\n",
       "      <td>149954.0</td>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>again</th>\n",
       "      <td>21063</td>\n",
       "      <td>18699</td>\n",
       "      <td>47.03</td>\n",
       "      <td>52.97</td>\n",
       "      <td>5.94</td>\n",
       "      <td>39762.0</td>\n",
       "      <td>again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomorrow</th>\n",
       "      <td>17188</td>\n",
       "      <td>23973</td>\n",
       "      <td>58.24</td>\n",
       "      <td>41.76</td>\n",
       "      <td>16.48</td>\n",
       "      <td>41161.0</td>\n",
       "      <td>tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>re</th>\n",
       "      <td>2126</td>\n",
       "      <td>2460</td>\n",
       "      <td>53.64</td>\n",
       "      <td>46.36</td>\n",
       "      <td>7.28</td>\n",
       "      <td>4586.0</td>\n",
       "      <td>re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theirs</th>\n",
       "      <td>152</td>\n",
       "      <td>116</td>\n",
       "      <td>43.28</td>\n",
       "      <td>56.72</td>\n",
       "      <td>13.44</td>\n",
       "      <td>268.0</td>\n",
       "      <td>theirs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>62414</td>\n",
       "      <td>76657</td>\n",
       "      <td>55.12</td>\n",
       "      <td>44.88</td>\n",
       "      <td>10.24</td>\n",
       "      <td>139071.0</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>having</th>\n",
       "      <td>7507</td>\n",
       "      <td>6988</td>\n",
       "      <td>48.21</td>\n",
       "      <td>51.79</td>\n",
       "      <td>3.58</td>\n",
       "      <td>14495.0</td>\n",
       "      <td>having</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             neg     pos  pos_ratio  neg_ratio  abs_diff     total     word_\n",
       "word                                                                        \n",
       "have      110465  104187      48.54      51.46      2.92  214652.0      have\n",
       "m           1262    1151      47.70      52.30      4.60    2413.0         m\n",
       "by         42010   35427      45.75      54.25      8.50   77437.0        by\n",
       "at         60308   57411      48.77      51.23      2.46  117719.0        at\n",
       "she        25201   32088      56.01      43.99     12.02   57289.0       she\n",
       "do         93985   90265      48.99      51.01      2.02  184250.0        do\n",
       "our        11178   14147      55.86      44.14     11.72   25325.0       our\n",
       "before      7379    7918      51.76      48.24      3.52   15297.0    before\n",
       "herself      318     234      42.39      57.61     15.22     552.0   herself\n",
       "into        6887    5165      42.86      57.14     14.28   12052.0      into\n",
       "am        104757  102878      49.55      50.45      0.90  207635.0        am\n",
       "than        9042   11936      56.90      43.10     13.80   20978.0      than\n",
       "being      23359   22881      49.48      50.52      1.04   46240.0     being\n",
       "rt           286     319      52.73      47.27      5.46     605.0        rt\n",
       "yourself    3622    4226      53.85      46.15      7.70    7848.0  yourself\n",
       "are        73282  106760      59.30      40.70     18.60  180042.0       are\n",
       "in        224068  206003      47.90      52.10      4.20  430071.0        in\n",
       "from       37442   31001      45.29      54.71      9.42   68443.0      from\n",
       "about      27967   34287      55.08      44.92     10.16   62254.0     about\n",
       "which       3734    3564      48.84      51.16      2.32    7298.0     which\n",
       "who        17303   25853      59.91      40.09     19.82   43156.0       who\n",
       "u          17262   23573      57.73      42.27     15.46   40835.0         u\n",
       "is        231631  253407      52.24      47.76      4.48  485038.0        is\n",
       "where      13330   10537      44.15      55.85     11.70   23867.0     where\n",
       "a           3744    3404      47.62      52.38      4.76    7148.0         a\n",
       "same       10951    8896      44.82      55.18     10.36   19847.0      same\n",
       "those       5397    6602      55.02      44.98     10.04   11999.0     those\n",
       "as         18376   26688      59.22      40.78     18.44   45064.0        as\n",
       "too        37404   40707      52.11      47.89      4.22   78111.0       too\n",
       "my        255742  252745      49.71      50.29      0.58  508487.0        my\n",
       "...          ...     ...        ...        ...       ...       ...       ...\n",
       "that      104636  140233      57.27      42.73     14.54  244869.0      that\n",
       "they       28936   28471      49.59      50.41      0.82   57407.0      they\n",
       "s           1254    1044      45.43      54.57      9.14    2298.0         s\n",
       "while       5449    6031      52.53      47.47      5.06   11480.0     while\n",
       "can        65690   72478      52.46      47.54      4.92  138168.0       can\n",
       "or         26332   24509      48.21      51.79      3.58   50841.0        or\n",
       "any        11209    9257      45.23      54.77      9.54   20466.0       any\n",
       "i         108975  121298      52.68      47.32      5.36  230273.0         i\n",
       "for       135543  145487      51.77      48.23      3.54  281030.0       for\n",
       "be          6806    6880      50.27      49.73      0.54   13686.0        be\n",
       "and       228597  206122      47.41      52.59      5.18  434719.0       and\n",
       "what      114135  114025      49.98      50.02      0.04  228160.0      what\n",
       "during      2417    3054      55.82      44.18     11.64    5471.0    during\n",
       "an           126      93      42.47      57.53     15.06     219.0        an\n",
       "his        13752   12444      47.50      52.50      5.00   26196.0       his\n",
       "over       21835   18587      45.98      54.02      8.04   40422.0      over\n",
       "most        8358    5963      41.64      58.36     16.72   14321.0      most\n",
       "own         4281    4910      53.42      46.58      6.84    9191.0       own\n",
       "after      10126   10043      49.79      50.21      0.42   20169.0     after\n",
       "when       46071   41480      47.38      52.62      5.24   87551.0      when\n",
       "to        341120  326481      48.90      51.10      2.20  667601.0        to\n",
       "once        3696    4747      56.22      43.78     12.44    8443.0      once\n",
       "whom         279     194      41.01      58.99     17.98     473.0      whom\n",
       "just       66559   83395      55.61      44.39     11.22  149954.0      just\n",
       "again      21063   18699      47.03      52.97      5.94   39762.0     again\n",
       "tomorrow   17188   23973      58.24      41.76     16.48   41161.0  tomorrow\n",
       "re          2126    2460      53.64      46.36      7.28    4586.0        re\n",
       "theirs       152     116      43.28      56.72     13.44     268.0    theirs\n",
       "all        62414   76657      55.12      44.88     10.24  139071.0       all\n",
       "having      7507    6988      48.21      51.79      3.58   14495.0    having\n",
       "\n",
       "[98 rows x 7 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_df.loc[stop_df.abs_diff<20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_words = list(stop_df.loc[stop_df.total<20].index) + ['user', 'url', 'rt', 'twitter', 'facebook']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tokens = [[t for t in tokens if len(t)>2] for tokens in pos_tokens\n",
    "             if len(tokens)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'zmq.backend.cython.message.Frame.__dealloc__'\n",
      "Traceback (most recent call last):\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 12, in zmq.backend.cython.checkrc._check_rc (zmq\\backend\\cython\\message.c:4294)\n",
      "    PyErr_CheckSignals()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "neg_tokens = [[t for t in tokens if len(t)>2] for tokens in neg_tokens \n",
    "              if len(tokens)>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tokens = []\n",
    "for tweet in test:\n",
    "    test_tokens.append([lemmatizer.lemmatize(w) for w in tokenize(tweet)])\n",
    "#test_tokens = [[t for t in tokens if t not in del_words and len(t)>2 and t in model.wv.vocab] for tokens in test_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens = [['empty'] if len(t)<1 else t for t in test_tokens ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(pos_tokens + neg_tokens + test_tokens, size=300, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('roommate', 0.5838409662246704),\n",
       " ('classmate', 0.5687693953514099),\n",
       " ('cousin', 0.5555226802825928),\n",
       " ('sister', 0.5229045152664185),\n",
       " ('girlfriend', 0.5219735503196716),\n",
       " ('roomie', 0.49464720487594604),\n",
       " ('husband', 0.47823768854141235),\n",
       " ('boyfriend', 0.4758955240249634),\n",
       " ('ie', 0.4735199809074402),\n",
       " ('teammate', 0.46988964080810547)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('friend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tweet2vector(tweet_tokens, model):\n",
    "    return sum([model[word] for word in tweet_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_vec = np.asarray([tweet2vector(tweet, model) for tweet in pos_tokens])\n",
    "neg_vec = np.asarray([tweet2vector(tweet, model) for tweet in neg_tokens])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate both\n",
    "X = np.vstack((pos_vec, neg_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [1 for i in range(len(pos_vec))] + [-1 for i in range(len(neg_vec))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_vec = np.asarray([tweet2vector(tweet, model) for tweet in test_tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(30, 30), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-1a154f38b9fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    971\u001b[0m         \"\"\"\n\u001b[0;32m    972\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[1;32m--> 973\u001b[1;33m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[0;32m    974\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m             self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n\u001b[1;32m--> 383\u001b[1;33m                             intercept_grads, layer_units)\n\u001b[0m\u001b[0;32m    384\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_lbfgs\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[0;32m    468\u001b[0m             \u001b[0miprint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miprint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m             \u001b[0mpgtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m             args=(X, y, activations, deltas, coef_grads, intercept_grads))\n\u001b[0m\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimal_parameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[1;32m--> 193\u001b[1;33m                            **opts)\n\u001b[0m\u001b[0;32m    194\u001b[0m     d = {'grad': res['jac'],\n\u001b[0;32m    195\u001b[0m          \u001b[1;34m'task'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[1;34m(*wrapper_args)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_loss_grad_lbfgs\u001b[1;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpacked_coef_inter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         loss, coef_grads, intercept_grads = self._backprop(\n\u001b[1;32m--> 179\u001b[1;33m             X, y, activations, deltas, coef_grads, intercept_grads)\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoef_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_backprop\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    255\u001b[0m             coef_grads, intercept_grads = self._compute_loss_grad(\n\u001b[0;32m    256\u001b[0m                 \u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef_grads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                 intercept_grads)\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef_grads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_grads\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_compute_loss_grad\u001b[1;34m(self, layer, n_samples, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \"\"\"\n\u001b[0;32m    125\u001b[0m         coef_grads[layer] = safe_sparse_dot(activations[layer].T,\n\u001b[1;32m--> 126\u001b[1;33m                                             deltas[layer])\n\u001b[0m\u001b[0;32m    127\u001b[0m         \u001b[0mcoef_grads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mcoef_grads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(np.arange(len(predictions))+1, predictions, 'submissions/prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
