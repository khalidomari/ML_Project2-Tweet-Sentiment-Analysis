{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from wordsegment import load, segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<user> i dunno justin read my mention or not . only justin and god knows about that , but i hope you will follow me #believe 15'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = [line.rstrip('\\n') for line in open('../data/train_pos.txt')]\n",
    "pos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from itertools import groupby\n",
    "from wordsegment import load, segment\n",
    "\n",
    "def check_dict(word, dictionary):\n",
    "    if word in dictionary:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def correct_char_repetition(word):\n",
    "    word = word.lower()\n",
    "    occurance = [(k, sum(1 for i in g)) for k,g in groupby(word)]\n",
    "    if len(occurance)==1: \n",
    "        return word\n",
    "    if max([j for (_,j) in occurance]) > 2:\n",
    "        corrected_word = ''\n",
    "        for (i,j) in occurance:\n",
    "            if j>2:\n",
    "                corrected_word += 2*i\n",
    "            else:\n",
    "                corrected_word += i*j\n",
    "        return corrected_word\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "dictionary = Counter(words(open('../data/english_words.txt').read()))\n",
    "\n",
    "def P(word, N=sum(dictionary.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return dictionary[word] / N\n",
    "\n",
    "def separate(words):\n",
    "    return segment(words)\n",
    "\n",
    "def correction(word): \n",
    "    #load()\n",
    "    \"Most probable spelling correction for word.\"\n",
    "    \n",
    "    #delete repeated letters\n",
    "    word = correct_char_repetition(word)\n",
    "\n",
    "    #if degits return it\n",
    "    if word.isdigit():\n",
    "        return word\n",
    "\n",
    "    if word in dictionary:\n",
    "        return word\n",
    "    else:\n",
    "       # segments = separate(word)\n",
    "       # if len(segments) > 1:\n",
    "       #     return ' '.join(word for word in segments)\n",
    "       # else:\n",
    "        return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in dictionary)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'k on nec zion'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load()\n",
    "correction('konneczion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
